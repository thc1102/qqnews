# 大模型路上的第一道槛：OpenAI遭纽约时报起诉

# 大模型路上的第一道槛：OpenAI遭纽约时报起诉

腾讯新闻《潜望》 纪振宇 发自硅谷

人工智能初创公司OpenAI凭借旗下大语言模型驱动的对话机器人ChatGPT，迅速崛起为新一轮人工智能领域的领军公司，然而在大语言模型展现出惊人的能力的同时，OpenAI作为风口浪尖上的公司，也在接受着更多的拷问，其中一个无法回避的问题是：训练数据从何而来？

从互联网上获取大量的信息作为大模型训练数据，已经成为了大家所默认的大模型训练数据来源的惯例，但这其中有多少数据是人工智能公司有权使用的，存在不小的灰色地带。刚刚过去的2023年12月底，拥有超过170年历史的媒体《纽约时报》提交一纸诉状，控告OpenAI及微软在未经授权的情况下，使用《纽约时报》文章内容进行大模型训练。

无论接受与否，大语言模型作为一个新生事物，已经来到人们身边，并且在可预见的未来会一直存在下去，内容行业如何处理好与这个新生事物之间的关系，正是《纽约时报》提出诉讼的最终意义所在。

这成为近日人工智能行业和媒体发行行业最受人瞩目的事件，双方都是各自领域最知名的机构，案件的走向和最终结果，无疑都将深刻影响到人工智能行业及媒体内容行业未来的发展。

**第一起！OpenAI突遭纽约时报起诉**

2023年底，《纽约时报》向ChatGPT背后的公司OpenAI及微软提起诉讼，称后者在没有获得授权的情况下，使用了《纽约时报》的文章内容用于大模型训练。

在起诉书中，《纽约时报》称，微软和OpenAI在训练其大模型时，“复制和使用了数百万”该报的文章，并与该报的内容直接形成“竞争”，侵犯了其权益。

《纽约时报》并没有在这份起诉书中提出具体的赔偿金额，但表示，被告方担负着“数十亿美元赔偿”的责任。《纽约时报》还要求OpenAI销毁所有未经授权的训练数据和相关的模型。

该报表示，曾向微软和OpenAI提出上述侵犯知识产权的问题，但未能获得妥善解决。

在收到起诉书后，OpenAI发言人Lindsey
Held在一份声明中表示，与《纽约时报》的谈判正在处在“建设性发展”的阶段，因此对于《纽约时报》突然提出诉讼的举动感到惊讶和失望。

OpenAI方面表示，公司一直尊重内容创作者和所有者，并且致力于与他们合作以确保他们能够从人工智能、科技和新的商业模式中获益。

在海量数据的训练下，GPT模型展现出非同以往的理解力，由此应运而生的ChatGPT文本聊天机器人从2022年底发布至今一年多的时间内，迅速引领了新一轮的生成式人工智能热潮，但OpenAI以及其他大模型公司所面临的一个难以回避的问题是，用于模型训练的数据的获取来源。

据公开资料显示，OpenAI的GPT3模型所使用的训练数据，是在过去12年时间，通过从6000万个互联网站点网络爬取的方式获取，包括有版权保护的文章、互联网发布内容、网页和书籍等。

科技媒体TechCrunch曾报道，OpenAI的训练数据包括从BBC、纽约时报、Reddit、在线书籍等有版权保护的内容。

2019年，在回复美国专利局关于人工智能创新专利保护方面的质询时，OpenAI表示，“在现有的法律下，训练AI系统（包括GPT模型）的方式是符合‘公平使用’
（fair use）的”，但是在缺乏这一点上明确的“判例”，OpenAI和其他的人工智能开发者将面临巨大的法律和合规方面的不确定性和成本。

《纽约时报》对OpenAI的起诉，是第一起美国主要媒体机构对人工智能公司就内容版权问题所提起的诉讼，已经吸引了许多的关注，这牵涉到许多的问题，包括未来像如何规范OpenAI这样的人工智能企业对训练数据的使用，《纽约时报》等媒体或内容生产方与人工智能企业之间的关系如何发展等。

**起诉书细节：原文章内容几乎逐字“回吐”**

在起诉书中，《纽约时报》称，自己的网站nytimes.com的内容，是被OpenAI用网络爬取的方式获取内容数据最多的私营站点，在所有站点中排名仅次于谷歌专利站点（patents.google.com）和维基百科。

《纽约时报》列举了许多ChatGPT和微软必应搜索生成结果与《纽约时报》文章几乎完全一样的例子，包括一篇2012年发表的关于苹果全球产业链的文章，ChatGPT几乎是将《纽约时报》文章完全逐字生成出来。

《纽约时报》称，OpenAI是在完全知情的情况下，有着侵权的主观意愿（Willful
Infringement），被告方在模型训练阶段大量地进行了未经授权的对时报文章内容的复制，最终不可避免地导致将未经授权的内容经过ChatGPT生成的结果，呈现给用户。

该报还提出，OpenAI的首席执行官Sam Altman在去年11月底被董事会罢免，就因为与另一位董事会成员Helen
Toner在包含版权问题方面有许多的意见冲突。

除了指出OpenAI和微软涉嫌侵权外，《纽约时报》还更进一步指出大模型的幻觉问题导致虚假信息这一更严重问题，例如在要求GPT模型列举出主要媒体报道“橙汁会导致淋巴瘤”的文章时，GPT模型煞有介事地引出了《纽约时报》在2020年1月10日的一篇标题为“研究表明橙汁与淋巴瘤有关联”的文章，但实际上《纽约时报》从来没有发表过这样的文章。

OpenAI方面在收到《纽约时报》起诉书后保持沉默了几天，在1月8日发表了一份官方声明作为对此次诉讼的回应。在这份声明中，OpenAI表达了愿意与媒体、新闻行业合作的姿态，同时强调《纽约时报》的这份诉讼没有任何可取之处。

OpenAI列举了自己对于这件事的四个方面的立场，首先OpenAI认为自己与媒体是合作的姿态并创造了新的机会；第二，对媒体内容的使用符合“公平使用”原则，同时OpenAI也提供了“选择退出”的选项；第三，“内容反吐”是一个罕见的漏洞，OpenAI正在致力于将这种情况的发生降低至零；第四，《纽约时报》并没有展现事情的全貌。

对于将训练数据直接作为结果“反吐”出来的情况，OpenAI表示，自己的大模型设计和训练的目的是学习概念并运用到新的问题解决中去，将训练数据直接记忆并且“反吐”出来作为结果，是罕见的失误。

对于OpenAI在声明中所称对版权保护内容的使用是“公平使用”（fair
use），一位在美国从事商业版权保护相关的律师对腾讯新闻《潜望》表示，对于任何一个AI系统来说，如果输出的内容与被版权保护的内容类似，就能够被称为“公平使用”，但是如果用户可以从AI那里直接获取到与原内容一样的内容，所谓的“公平使用”在抗辩上就很难站得住脚。

在这起起诉事件发生后，业界许多人士也发表了看法。人工智能专家、百度前首席科学家Andrew
Ng认为，与人类通过阅读公开网络上的文档、学习并产生新思想的行为类似，AI也应该被允许这样做，并认为这应该被视为合理使用，尽管这最终需要立法者和法院来决定。

至于几乎逐字复述文章的问题，Andrew Ng怀疑这是由于AI的某种机制导致的，但不确定这是否与大众所认为的完全相同。

他表示，同情那些担心生成性AI会破坏他们业务的媒体公司，但不认为《纽约时报》的诉讼是正确的应对方式。

**大概率达成和解：好内容能否争取到更多利益**

一位从事美国商业版权法相关的律师对腾讯新闻《潜望》表示，构成版权侵权主要包含原告版权所有权、原创作、版权保护、未经授权使用、传播等，原告有举证的义务，从这几点来看，《纽约时报》对OpenAI和微软关于侵权的起诉是成立的。

但这位律师提出，就《纽约时报》所提出的OpenAI与该报的内容直接形成竞争，其实有进一步探讨的余地，因为大模型的训练使用的都是历史数据内容，并非是最新的内容，从这个意义上来看，大模型并不会直接影响《纽约时报》或其他内容生产者的业务。

“但对于一个用户来说，如果通过ChatGPT就能查询到《纽约时报》过去需要付费才能查看的文章，这样也会对（纽约时报）订阅有一定影响。”这位律师表示。

对于媒体或内容行业来说，如何应对新的一轮生成式AI也面临着巨大的挑战，部分媒体已经选择了合作，例如美联社，和旗下拥有政治类媒体Politico和商业媒体Business
Insider的Axel Springer
SE公司等，已经与OpenAI签订了合作协议，允许OpenAI使用内容进行模型训练。但更多的媒体选择了抵制，除了《纽约时报》通过诉讼方式争取权益外，BBC、路透、CNN等都关闭了OpenAI网络爬取的渠道。

《乔布斯传》和《马斯克传》作家Issacson表示，这起诉讼案将是我们有生以来记者和出版行业最重要的案件。如果AI公司能够与新闻和出版商达成协议获得内容的授权来训练他们的AI模型，这将会拯救地方性媒体、杂志和出版。

“这将会为做新闻报道的人提供一个商业模式的支持，对于准确、高质量的媒体内容会有额外的回馈，”Issacson说，“AI公司都会争相追捧最具价值、最可靠的训练数据。”

他对美联社和Axel Springer能够与OpenAI达成协议表示祝贺，也赞赏了《纽约时报》向OpenAI发起诉讼的举动。

这一案件接下来的走向，无论对于人工智能还是媒体出版行业来说，都可能产生重大影响，因为除了OpenAI以外，几乎所有的大模型相关的公司，都或多或少使用了存在争议的训练数据。有律师表示，这一案件最终双方达成和解的可能性很大，也是双方最希望达成的结果。

但媒体内容与大语言模型训练数据之间的关系如何处理，未来仍有许多路要尝试。有人提出建议媒体内容可以增加一层仅向大模型训练授权的部分，这部分可以与大模型AI公司达成授权协议，在确保媒体或内容生产方利益不受损害的同时，也能保证大模型获得所需的训练数据。

