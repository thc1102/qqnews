# OpenAI大模型上身机器人，原速演示炸场

# OpenAI大模型上身机器人，原速演示炸场

编辑部 发自 凹非寺

量子位 | 公众号 QbitAI

OpenAI大模型加持的机器人，深夜来袭！

名曰**Figure 01** ，它能听会说，动作灵活。

能和人类描述眼前看到的一切：

我在桌子上看到了一个红色的苹果，沥水架上面还有几个盘子和一个杯子；然后你站在附近，手放在桌子上。

听到人类说“想吃东西”，就马上递过去苹果。

而且对于自己做的事有清楚认知，给苹果是因为这是桌上唯一能吃的东西。

还顺便把东西整理，能**同时搞定两种任务** 。

最关键的是，这些展示都**没有加速** ，机器人本来的动作就这么迅速。

（也没人在后面操纵）

这下网友坐不住了，立马@波士顿动力：

老伙计们，这家伙是真来劲儿了。咱得回实验室，让以前的机器人（波士顿动力）多跳点舞了。

![](https://inews.gtimg.com/news_bt/OMPNUopyHB2NNcyZrqidueZFjqNoP9p9lPyCc8TNUON_YAA/1000)

也有网友看在OpenAI卷完大语言模型、文生视频之后，又狙击机器人后感慨道：

这是一场激烈的竞争；与OpenAl合作，苹果可能会超越特斯拉。

但硬件方面，擎天柱看起来更美观，Figure 01仍然需要一些“整容手术”。（doge）

![](https://inews.gtimg.com/news_bt/OLGy_C2PKaRW3jfC9zlkHEo4r9-6-53IeCd_Izp1zUYEIAA/1000)

接下来，我们继续来看下Figure 01的细节。

OpenAI视觉语言大模型加持

根据创始人的介绍，Figure 01通过端到端神经网络，可以和人类自如对话。

基于OpenAI提供的视觉理解和语言理解能力，它能完成快速、简单、灵巧的动作。

模型只说是一个视觉语言大模型，是否为GPT-4V不得而知。

![](https://inews.gtimg.com/news_bt/OHzP0hzj7RyALYE30Dz1DJZYalX7HhoJTj19OXmvCSloUAA/1000)

它还能规划动作、有短期记忆能力、用语言解释它的推理过程。

![](https://inews.gtimg.com/news_bt/OjTGtMbWbxV5QTb8ED68u9oe_wdFLre4Fxe2eLKeFHnIQAA/1000)

比如对话里说“你能把它们放在那里吗？”

“它们”、“那里”这种模糊表述的理解，就体现了机器人的短期记忆能力。

它使用了OpenAI训练的**视觉语言模型** ，机器人摄像头会以10Hz拍下画面，然后神经网络将以200Hz输出**24自由度**
动作（手腕+手指关节角度）。

具体分工上，机器人的策略也很像人类。

复杂动作交给AI大模型，预训练模型会对图像和文本进行常识推理，给出动作计划；

简单动作如抓起塑料袋（抓哪里都可以），机器人基于已学习的视觉-动作执行策略，可以做出一些“下意识”的快速反应行动。

同时全身控制器会负责保持机身平衡、运动稳定。

机器人的语音能力则基于一个文本-语音大模型微调而来。

![](https://inews.gtimg.com/news_bt/OsVi1tNmfGbEuXniT41WWbtHjt41-64-rkwH2TaUk4HXIAA/1000)

除了最先进的AI模型，Figure 01背后公司——Figure的创始人兼CEO还在推文中提到，Figure方面整合了机器人的所有关键组成。

包括电机、中间件操作系统、传感器、机械结构等，均由Figure工程师设计。

据了解，这家机器人初创公司在2周前才正式宣布和OpenAI的合作，但才13天后就带来如此重磅成果。不少人都开始期待后续合作了。

![](https://inews.gtimg.com/news_bt/On6mIk_knMu8OEcXDzaEjxzBafpSE0PCuzkaB3YMN3c-sAA/1000)

由此，具身智能领域又有一颗新星走到了聚光灯下。

“将人形机器人带进生活”

说到Figure，这家公司创立于2022年，正如前文所言，再次引爆外界关注，就在十几天前——

官宣在新一轮融资中筹集6.75亿美元，估值冲到26亿美元，投资方几乎要集齐半个硅谷，包括微软、OpenAI、英伟达和亚马逊创始人贝佐斯等等。

更重要的是，OpenAI同时公开了与Figure更进一步合作的计划：将多模态大模型的能力扩展到机器人的感知、推理和交互上，“开发能够取代人类进行体力劳动的人形机器人”。

用现在最热的科技词汇来说，就是要一起搞**具身智能** 。

![](https://inews.gtimg.com/news_bt/OnY5mct7FmN2qzxfB3DRTch7LpWsrJ3a9iK1cmLMg6yJIAA/1000)

彼时，Figure 01的最新进展是酱婶的：

通过观看人类的示范视频，仅需10小时端到端训练，Figure 01就能学会用胶囊咖啡机泡咖啡。

Figure与OpenAI的合作一公开，网友们就已经对未来的突破充满了期待。

![](https://inews.gtimg.com/news_bt/OVNS0s-TXIE11Wliv1ZJcQXT4Nnwx03fFKMImOvex_YioAA/1000)

毕竟Brett Adcock，可是把“唯一的重点是以30年的视角建立Figure，以积极影响人类的未来”这样的话都写在个人主页上了。

但可能没人能想得到，仅仅两周左右的时间，新进展就来了。

如此之快，如此之远。并且还能持续泛化、扩展规模。

![](https://inews.gtimg.com/news_bt/O1YmX9P3CkQYBD3AssP3KdK7_RpXHKFW1RuaGKBX_JSkMAA/1000)

值得一提的是，与炸场demo同时发布的，还有Figure的招聘信息：

我们正在将人形机器人带进生活。加入我们。

![](https://inews.gtimg.com/news_bt/OPTheXM6EZtNpbMLIOmGGeD377SDeCCpFPrz7e8H-r2EYAA/1000)

参考链接：

[1]https://twitter.com/figure_robot/status/1767913661253984474?s=46&t=HBob6gxh8cOfZTIbieKeSA

[2]https://twitter.com/adcock_brett/status/1767913955295744449

[3]https://twitter.com/coreylynch/status/1767927194163331345

— 完 —

