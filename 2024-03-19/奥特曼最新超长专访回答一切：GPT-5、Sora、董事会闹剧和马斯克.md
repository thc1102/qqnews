# 奥特曼最新超长专访回答一切：GPT-5、Sora、董事会闹剧和马斯克

# 奥特曼最新超长专访回答一切：GPT-5、Sora、董事会闹剧和马斯克

![](https://inews.gtimg.com/news_bt/O2WOzXnQWEpM7Agn7bZzdT1J7LZz3BUgsT4XARYA6V9qkAA/1000)

腾讯科技讯 3月19日消息，据国外媒体报道，美国知名播客莱克斯·弗里德曼（Lex
Friedman）近期再次邀请人工智能领域的领军人物、OpenAI首席执行官山姆·奥特曼（Sam
Altman）进行专访。这次对话，奥特曼不仅深入剖析了OpenAI董事会近期的变动，还畅谈了首席科学家伊利亚·苏茨凯弗（Ilya
Sutskever）的未来动向、与埃隆·马斯克（Elon
Musk）之间的法律纷争，以及备受瞩目的文字转视频工具Sora、豪掷7万亿美元的芯片计划、即将推出的新一代大语言模型GPT-5，乃至通用人工智能（AGI）的远景规划等。

以下为此次专访实录全文：

01 OpenAI董事会风波

**问：** 请带我们回顾下从2023年11月16日周四开始的OpenAI董事会风波，也许是11月17日周五。

**奥特曼：**
那绝对是我一生中最痛苦的职业经历，充满了混乱、羞耻、沮丧以及其他一大堆负面的东西。不过，其中也不乏值得珍藏的美好瞬间。我希望自己当时能够保持冷静，不被过度的肾上腺素冲昏头脑，从而能够停下来细细品味那些宝贵的经历。

但当我看到那时候发的推文时，感觉这就像自己的悼词，记录着人们在那个特殊时期对我的赞美和支持。看到这些推文，我深感欣慰，也感受到了身边人的爱与关心。真是太棒了！整个周末，尽管遭遇了一些不愉快的事情，但总体而言，我感受到的爱远远超过了恨。

尽管我不知道到底发生了什么，也不知道将要发生什么，这感觉真的很糟糕。确实有很多时候，我认为这将是人工智能安全有史以来最糟糕的事情之一。但我也很庆幸这一切发生得相对较早。我认为，在OpenAI成立和通用人工智能（AGI）诞生的过程中，注定会有一系列疯狂且具有爆炸性的事件发生。这些事件虽然令人不安，但也为我们提供了宝贵的经验和教训，为未来应对更多挑战做好了准备。

**问：** 但你自己有一种感觉，你会经历某种权力斗争？

![](https://inews.gtimg.com/news_bt/OoTbT7wJZb3hBpuZ0LYwZpoyHa_BeBVxCDWKLYvftZcdMAA/1000)

**奥特曼：** 确实，通往通用人工智能的道路可能会涉及多方面的权力斗争。我希望是这样。

**问：**
所以，你必须要经历这些。正如您所言，我们需要深思熟虑如何构建董事会架构，如何有效组织，以及如何与合作伙伴沟通，力求在最大程度上减少权力斗争的发生。

**奥特曼：**
是的。回首过去，那段经历确实令人不悦，充满了艰难和痛苦。然而，当我们重新投入工作时，繁忙和紧张的节奏让我无暇过多沉湎于过去的情绪。在那之后的一个月，也许是45天里，我仿佛处于一种游离的状态，每天都像是在漂泊，思绪并不清晰。那时的我，情绪异常低落，仿佛被阴影笼罩。

**问：**
你对董事会审议过程的参与度和严谨性有了解吗？你能谈谈在这种情况下涉及的人际关系动态吗？是不是只是几次对话，然后事态突然激化，然后就有人提出“为什么我们不解雇山姆”之类的建议？

**奥特曼：**
我认为董事会成员总体上都是出于好意的人，我相信在那种压力环境下，人们感到时间紧迫或其他什么，人们会做出不那么明智的决定都可以理解。我认为OpenAI面临的挑战之一将是，我们需要有一个擅长在压力下运作的董事会和团队。

**问：** 你认为董事会的权力过大了吗？

**奥特曼：**
我认为董事会应该有很大的权力，但我们确实看到的一件事是，在大多数公司架构中，董事会通常要对股东负责。有时人们拥有超级投票权或其他什么。在这种情况下，我认为我们结构中的一个问题是，我们可能没有充分考虑到非营利组织董事会实际上掌握着很大的权力，除非你有其他规定。他们并不真正向任何人负责，基本上只对自己负责。这在某些方面是好的，但我们真正希望的是OpenAI的董事会能够对整个世界负责，尽管这在实践中可能很难实现。

**问：** 所以你们宣布组建新的董事会。

**奥特曼：** 是的。

**问：** 我想一开始有一个新的、规模较小的董事会，现在有一个新的最终董事会吗？

**奥特曼：** 还不是最终的董事会。我们增加了一些人，还会增加更多。

**问：** 在新的董事会中，有哪些是之前那个董事会中可能存在的问题，现在得到了解决？

**奥特曼：**
原董事会在一年的时间里规模变小了。原本是九个人，后来减少到六个人，然后我们无法就新增成员达成一致。此外，我认为董事会也没有太多经验丰富的董事会成员，而OpenAI的很多新董事会成员在作为董事会成员方面更有经验。我认为这将有所帮助。

问：有人批评了新加入董事会的一些人。例如，我听到了很多人批评拉里·萨默斯（Larry
Summers）的加入。那么选择董事会成员的过程是怎样的？涉及哪些因素？

**奥特曼：** 选择布雷特·泰勒（Bret
Taylor）和萨默斯为董事会成员是在那个非常紧张的周末做出的决定，而那个周末真是就像坐过山车一样，给人一种大起大落的感觉。我们试图就新的董事会成员达成一致，这些成员既要让这里的执行团队感到满意，也要得到原董事会成员的认可。

实际上，萨默斯是原董事会成员推荐的人选之一。至于布雷特，我想在那个疯狂周末之前，我就提议过他，但他当时很忙，不想接受这份工作。之后，我们确实需要帮助，他才加入进来。我们也考虑了很多其他人选，但我觉得如果我回来的话，我需要更换新的董事会成员。我不认为我可以在同样的人员配置下再次与原董事会合作，尽管后来我们决定让亚当·德安吉洛（Adam
D'Angelo）留下。但我们考虑了各种配置，最终决定想要组建一个三人的董事会，并需要短时间内找到两名新的董事会成员。

所以那些决定确实是直接做出的，你必须在战场上迅速做出决定。那时你没有时间设计严格的流程。对于之后的新的董事会成员，以及我们还将要继续添加的新成员，我们有一些认为对董事会来说重要的标准，我们希望这些人具备的不同专长。与招聘一名高管不同，他只需要把一个角色做好，但对于董事会成员来说，他需要需要在治理和思考方面表现出全方位的能力。因此，布雷特说的一句话我很认同，那就是我们想要以成批的形式招聘董事会成员，而不是一次一个地招聘。我们正在考虑的是一群能够带来非营利组织专业知识、公司运营专业知识、良好的法律和治理专业知识的人，这是我们试图优化的目标。

**问：** 那么，对于单个董事会成员来说，技术素养重要吗？

**奥特曼：** 不是每个董事会成员都需要这类素养，但确实有一些人需要。这也是董事会职责一部分。

**问：**
关于OpenAI，人们可能不了解的有趣的一点是，我当然也不了解，那就是经营公司的所有细节。当人们想到董事会时，鉴于其中的戏剧化元素，他们可能首先会想到你。他们会想：如果你开发出AGI或你创造出一些极具影响力的产品，并成功将它们推向市场，你和董事会之间的对话会是什么样的？他们可能还会想：在那种情况下，应该有什么样的合适团队来进行决策和讨论？

**奥特曼：**
我认为，董事会中确实需要一些技术专家。同时，你需要一些能够思考“我们如何部署这项技术才能最大限度造福人类？”的人，还需要一些持有不同观点的人。我认为你我可能会犯的一个错误是，认为只有理解技术才是挑选董事会成员的重要标准，这当然是董事会应该讨论的一部分，但关于这项技术将如何影响社会和人们的生活，你也也同样希望能够在董事会中得到体现。

**问：** 你在考虑人选时，是更看重他们的过往经历，还是只是与他们交谈即可？

**奥特曼：** 过往经历很重要。当然，你们会进行很多交谈，但有些职位我完全不看重过往经历，只看他的上升势头，忽略掉Y轴的截距。

**问：** 谢谢。谢谢你为观众用数学的方式做出解释。

**奥特曼：** 对于董事会成员，我确实更看重Y轴截距。我认为过往经历中有一些深刻的东西可以说，经验是很难被替代的。

**问：** 你尝试将过往经历拟合为多项式函数还是指数函数？

**奥特曼：** 这个类比不太合适。

**问：**
好的。你之前提到了那个疯狂周末遭遇的一些低谷。对你来说，心理上还有哪些低谷？你有没有考虑过去亚马逊丛林里喝下亚胡阿斯卡（一种致幻剂），然后永远消失？

**奥特曼：**
那是一段非常糟糕的时期。当然，也有一些很棒的时刻。我的手机不断收到与我日常合作的人以及那些我已经十年没联系过的人发来的关怀信息。因为我当时正处于危机之中，因此没有太多时间去回应，没能充分感受到这份温暖，但这确实让人感到很棒。总的来说，那是一个非常痛苦的周末。就像是在公众面前进行的一场战斗，让我感到非常疲惫，比我预想的还要难受。我认为争斗通常都很累人，但这次真的特别疲惫。董事会是在周五下午做出决定的。我并没有得到太多答复，但我也认为，董事会有权这么做，所以我会稍微花点时间思考一下我接下来想做什么，但我也会努力从中找到隐藏的祝福。

我当时心想，我目前在OpenAI的工作，或者之前的工作，是经营一家规模相当大的公司。而我一直最喜欢的事情就是与研究者们一起工作。然后我就想，我可以非常专注地去做AGI的研究工作。我开始对这个想法感到兴奋。当时我甚至没有想到这一切都会化为泡影。那已经是周五下午了。

**问：** 所以你接受了这样的终结——

**奥特曼：**
非常快，真的非常快。我经历了一段短暂的迷茫和愤怒，但这种负面状态很快就过去了。到了周五晚上，我已经在和别人讨论下一步要做什么了，而且我对此感到很兴奋。我记得是周五晚上，我第一次从这里的执行团队那里听到消息，他们说：“嘿，我们要抗争到底。”然后我就去睡觉了，心里还是想着：我很兴奋，继续前进！

**问：** 你睡得好吗？

**奥特曼：** 根本就没怎么睡。奇怪的是，有一段四天半的时间，我睡得很少，吃得也不多，但还是精力充沛。战时你会学到一些关于肾上腺素的奇怪事情。

**问：** 所以你接受了这样的结局，OpenAI这个被你视为“孩子”的公司迎来了失败的一天。

**奥特曼：** 我对新的事物都感到兴奋。我心想：“行吧，这玩意儿确实疯了点，但管它呢！”

**问：** 这是一个很好的应对机制。

**奥特曼：**
然后到了周六早上，两位董事会成员打来电话说：“嘿，我们不想搅局。我们不想在这里储存太多价值。我们能谈谈你回来的事吗？”最初，我不想回去，但后来又仔细地想了想，我还是觉得，我真的很关心这里的人、合作伙伴和股东们。我爱这家公司。所以我对他们说：“好吧，但我有自己的条件。”然后在那个周末最痛苦的时候，我一直在反思，也被告知，不仅仅是我，整个团队都在想，我们试图努力维持OpenAI的稳定，而那时整个世界都在试图让它分崩离析，人们试图招募我们的人。

我们一直被告知：“好了，我们快要弄完了。我们快要完成了。我们只需要再多一点点时间。”这是一种非常混乱的状态，直到周日晚上，我几乎每隔几个小时就期待这种混乱能够结束，找到一种让我回去的方法，让事情恢复到原来的样子。但董事会随后任命了一位新的临时首席执行官，我当时就觉得，这感觉真的很糟糕。那是整个事件的最低谷时刻。我告诉你，这感觉很痛苦，但整个周末我感受到了很多关怀。除了周日晚上的那一瞬间，我不会用愤怒或仇恨来形容我的情绪，但我感受到了人们对我的爱。虽然痛苦，但那个周末的主导情绪是爱，而不是恨。

**问：** 你曾高度赞扬了米拉·穆拉蒂（Mira
Murati），你说她在你推文中提到的关键时刻给予了你特别帮助。也许我们可以稍微偏离一下主题。你欣赏穆拉蒂哪些品质？

**奥特曼：**
她在那个周末的混乱中做得很好，人们往往在危机时刻才会关注领导者的表现，无论是好是坏。但我真正欣赏这类领导者的一点是，他们在平凡的周二早上9点46分和日常繁琐工作中是如何表现的。他们如何出席会议，他们做决策的质量如何。这就是我所指的“静默时刻”。

**问：** 这意味着大部分工作都是在日复一日、一次次的会议中完成的。只要保持专注，并做出明智的决策即可。

**奥特曼：**
是的。你看，过去20分钟你想谈论的，我理解的，是那一个非常疯狂的周末，但那并不是OpenAI的真正意义所在。OpenAI真正重要的是过去的七年。

**问：** 嗯，确实如此。人类文明可不仅仅关于纳粹德国入侵苏联，尽管人们仍然关注这一点。

**奥特曼：** 这是完全可以理解的。

02 苏茨凯弗还有另一面

**问：**
它能帮助我们洞察人性，人性的极端，也许人类文明的某些成就和某些损害就是在这些时刻发生的。人类文明的某些毁坏和伟大成就得以显现，因此这非常具有启发性。下面，让我问你关于伊利亚·苏茨凯弗（Ilya
Sutskever）的事情。他是不是被劫持在一个秘密的核设施里充当人质？

**奥特曼：** 当然不是。

**问：** 那是被藏在普通的秘密设施里？

**奥特曼：** 也不是。

**问：** 这事儿都快成梗了。你认识伊利亚很久了，对吧？他显然卷入了董事会那场风波，还有那一大堆乱七八糟的事情。你现在和他关系怎么样？

**奥特曼：**
我依然喜欢伊利亚。我非常尊重他。关于他现在的计划，我无可奉告。那是他的问题，该由他来回答。但我真的很希望在我职业生涯的剩余时间里，我们能继续一起工作。他比我年轻一些，也许他还会再工作久一些。

**问：** 有一个搞笑梗说伊利亚好像看到了什么东西，比如他可能看到了通用人工智能，这让他内心充满了忧虑。伊利亚到底看到了什么？

**奥特曼：**
伊利亚从来没有看到通用人工智能。我们任何人都没有看到过。我们还没有开发出通用人工智能。不过，伊利亚身上有很多让我敬佩的品质，其中之一是他非常重视通用人工智能及其广泛的安全问题，包括这项技术将对社会产生的影响。随着我们继续取得重大进展，伊利亚是过去几年里我花最多时间讨论这将意味着什么的人之一，讨论我们需要做什么来确保我们做得正确，确保我们成功地完成使命。所以，虽然伊利亚没有看到通用人工智能，但他在思考并确保我们在这个过程中做得正确，这对人类来说是一份巨大贡献。

**问：**
我以前和他聊过很多次。我认为当他谈论技术时，总是进行这种长期思考。所以他不是在想一年后会怎么样，而是在想十年后的事情，只是从首要原则开始思考，比如“好吧，如果这项技术能够扩展开来，这里的根本要素是什么？它将走向何方？”
这也是他思考所有其他安全问题和所有类似问题的基础，这使得与他交谈非常有趣。你知道他为什么近来变得沉默了吗？他是在进行自我反思吗？

**奥特曼：** 再次强调下，我不想代表伊利亚发言。我觉得你应该问问他本人。他确实是一个习惯深入思考的人。我觉得伊利亚总是在以一种非常好的方式进行灵魂探索。

**问：** 对，没错。而且，他也很懂得沉默的力量。另外，我听说他有时也挺逗的，但我从没见过他那一面。

**奥特曼：** 那样的他真的很可爱。

**问：** 我从没见过逗比的伊利亚，但我也很期待看到那一面。

**奥特曼：** 我最近和他一起参加了一个晚宴，他当时正在和一只小狗玩，心情非常放松，那场景相当温馨！我当时就想，哇，这不是世界最常见的伊利亚。

**问：** 那么，就这整桩事情而言，你对董事会的架构满意吗？

**奥特曼：** 是的。

**问：** 关于这一切及其走向，你有什么看法？

**奥特曼：**
我对新组建的董事会感觉很满意。在OpenAI的架构方面，董事会的一项职责就是要审视并找出我们可以使其更加稳健的地方。我们原本想先安排新的董事会成员到位，但显然，在这个过程中，我们在结构方面学到了一个教训。我觉得我没有太多深刻的见解要说。这是一次疯狂、非常痛苦的经历。我觉得这是各种奇怪情况的完美风暴。这次经历让我预见到了未来的挑战：随着赌注的提高，我们将需要更加稳健的治理结构和流程，以及更加合适的人选。我很高兴这件事发生在我还年轻的时候，但经历它确实非常痛苦。

**问：** 这件事会让你在信任他人时变得更加犹豫吗？

**奥特曼：** 会。

**问：** 只是在个人层面吗？

**奥特曼**
：是的。我自认为是一个非常信任他人的人。我的人生哲学一直是不要过于担忧所有的偏执狂想，不要担心那些边缘情况。即便你稍微吃点亏，换来的是可以放下防备地生活。然而，这次经历对我来说太震撼了。我完全措手不及，它确实改变了我。我真的不喜欢这种感觉，但它确实改变了我对人的默认信任和对糟糕情况的应对方式。

**问：** 你得在这方面小心一点。你担心自己会变得过于愤世嫉俗吗？

**奥特曼：** 我不担心自己会变得过于愤世嫉俗。我认为自己与愤世嫉俗的人截然相反，但我担心自己会变得不那么容易信任他人。

**问：**
实际上，对于正在开发通用人工智能（AGI）的人来说，我不清楚应该选择信任模式还是不信任模式来行动才是最好的。这是一次有趣的旅程。但在结构方面，我更关注人性层面。你如何让自己身边围绕着既能构建出色事物，又能做出明智决策的人？因为随着你开始赚更多的钱，这个东西拥有更大影响力，周围的人们可能会变得越来越奇怪。

**奥特曼：**
关于董事会成员以及我应该持有的信任程度，或者我应该如何以不同的方式行事，你可以提出各种看法。但就这里的团队而言，我想你会给我非常高的评价。我对我每天一起工作的人们怀有巨大的感激、信任和尊重，我认为被这样的人们包围着真的非常重要。

03 关于马斯克的诉讼

**问：** 我们共同的朋友马斯克起诉了OpenAI。你认为他批评的实质问题是什么？他有多少批评能站得住脚？又有多少是错的？

**奥特曼：**
我真的不知道这究竟是怎么回事。我们一开始只是想成为一个人工智能研究实验室，对这项技术将如何发展一无所知。因为那是七八年前的事了，现在想回忆起当时的情况真的很难。那时大语言模型还没有成为人们关注的热门话题。我们还没想到要开发API或销售聊天机器人访问权限，也没有想过要将其产品化，我们只是想，“我们要努力做研究，但我们真的不知道要用它做什么。”我认为，对于许多全新的事物来说，你开始时总是摸着石头过河，做一些假设，其中大多数最后都被证明是错误的。

然后，我们逐渐明确需要采取不同的做法，并且需要更多的资金。所以我们说，“行吧，现在的结构并不适合这些。我们如何调整结构呢？”然后你只能一次次地修补它，最后你得到的东西至少看起来不禁让人皱眉。但我认为，我们是一步一步地逐渐走到这里的，每个阶段都做出了合理的决策。这并不意味着如果有机会回到过去，我会完全采取不同的做法，但问题是当时我们并没有先知。不管怎样，至于埃隆真正的动机是什么，我真的不清楚。

**问：** 就你所记得的，OpenAI在博客文章中是如何回应埃隆诉讼的？你能概括一下吗？

**奥特曼：**
哦，我们只是提到了埃隆提出的一系列观点。这是我们的陈述，或者这不是我们的陈述。这是对这件事发生过程的描述。我们尽量不带有个人情绪，只是陈述，“这就是历史。”

**问：**
我认为埃隆在这里对你刚才提到的一点有些误解，那就是你们当时的不确定性程度有多大。你们只是有几个人的研究团队，疯狂地谈论着AGI，而当时所有人都在嘲笑这个想法。

**奥特曼：** 不久之前，埃隆还在疯狂地谈论发射火箭，而当时人们也在嘲笑这个想法，所以我认为他会对这件事产生更多共鸣。

**问：** 我认为这里确实有一些个人因素，OpenAI和许多这里的杰出人才选择与埃隆分道扬镳，所以存在个人层面的因素——

**奥特曼：** 是埃隆选择分道扬镳。

**问：** 你能具体描述一下当时你们分道扬镳的情况吗？

**奥特曼：**
他认为OpenAI将会失败，他希望能够完全掌控并扭转局势。而我们则希望继续朝着现在OpenAI的方向前进。他还希望特斯拉能够开展AGI项目。在不同时期，他都想把OpenAI变成一家盈利公司，由他掌控，或者与特斯拉合并。但我们不想这么做，于是他决定离开，这其实挺好的。

**问：**
所以你的意思是，正如OpenAI博客文章中也提到的，他希望OpenAI能被特斯拉收购，或许是与微软的合作方式有点相似，或者说可能是一种更为戏剧化的形式。

**奥特曼：** 我记得当时的提议就是，是的，被特斯拉收购，并让特斯拉完全控制它。我很确定提议就是这个意思。

**问：**
那么，在当时的情况下，OpenAI这个词中的“open”对埃隆来说意味着什么？伊利亚在电子邮件交流和其他一些内容中谈到了这一点。在当时，这个词对你意味着什么？现在对你又意味着什么？

**奥特曼：**
如果能够重新来过，我会选择一个不同的名字。我认为OpenAI正在做的最重要的事情之一，就是将强大的技术免费地交到人们手中，作为一种公共福利。我们没有在免费版本上投放广告，也没有以其他方式将其商业化。我们只是认为这是我们的使命，即将越来越强大的工具免费交到人们手中，并让他们使用它们。我认为这种“开放”对我们的使命来说非常重要。我认为，如果你给人们提供绝佳的工具，并教他们如何使用，或者甚至不用教他们，他们自己也会摸索出来，然后让他们用这些工具共同构建一个不可思议的未来，这将是意义重大的。因此，如果我们能够继续向世界推出免费或低成本甚至免费的强大AI工具，这将极大地推进我们的使命。至于是否“开源”，我认为我们应该对一些东西开源，而对另一些则不开源。这往往会变成一场宗教般的信仰之争，很难保持中立，但我认为找到平衡点才是正确的答案。

**问：** 埃隆已经说过：“如果你们将公司名字改成CloseAI，我就放弃诉讼。”我意思是说，这会变成关于名字的梗吗？

**奥特曼：** 我觉得这反映了埃隆对这次诉讼的认真态度，我认为这样说真是令人惊讶。

**问：** 也许我说得不对，但我不认为这次诉讼在法律上是严肃的。更多的是为了表明对AGI未来和目前领先公司的看法。

**奥特曼：**
看，我的意思是，直到人们指出这有点虚伪之前，Grok并没有开源任何东西。然后，埃隆才宣布Grok本周将开源一些东西。我不认为开源与否是他真正关心的问题。

**问：**
好的，我们会谈谈开源与不开源的问题。我倒是觉得，也许批评竞争对手是件好事，只是稍微抱怨一下也无伤大雅。但这得是建立在友好竞争的基础上，比起来，我个人真是非常讨厌打官司。

**奥特曼：**
我认为整件事都不像一个建设者应该做的。我尊重埃隆。他是我们这个时代最伟大建设者之一。我知道他了解被仇恨者攻击的滋味，这让我感到格外难过，他居然也这样做。

**问：** 是的，他可以说是有史以来最伟大的建设者之一，甚至可能是有史以来最伟大的建设者。

**奥特曼：**
这让我感到难过。我认为这也让很多人感到难过。有很多人长期以来一直仰慕他。我在接受采访时也曾经说过，我怀念以前的埃隆，结果我收到了很多回复，他们都说：“你的话完全表达了我的心声。”

**问：**
我认为他应该直接获胜。他应该让X的Grok击败GPT，然后GPT再反过来击败Grok，这就是竞争，对每个人来说都是一件好事。但关于开源的问题，你认为有很多公司在探索这个概念吗？这很有趣。我觉得Meta在这方面出人意料地走在了前面，或者至少是在真正开源模型这场棋局中迈出了第一步。当然，他们开源的并不是最尖端的模型，不过他们开源了
Lama。谷歌也在考虑开放一个规模较小的版本。开源有什么优缺点？你自己有没有思考过这个问题？

**奥特曼：**
是的，我认为开源模型确实有其存在的必要，特别是那些人们可以在本地运行的小型模型，我认为这方面的需求非常大。我想将来会有一些开源模型，也会有一些闭源模型。在这方面，它与其他生态系统并无不同。

**问：** 我听了所有与这次诉讼和其他相关话题有关的播客。他们更关心的是从非营利组织转变为这种盈利上限结构的先例。这对其他初创公司来说会树立什么样的先例？

**奥特曼：** 我会强烈反对任何打算以非营利组织起步，后来再增加盈利部门的初创公司。我会强烈反对他们这样做。我不认为我们会在这里树立先例。

**问：** 以这种方式创业，初创公司是不可能节省很多钱的。

**奥特曼：** 没错。我觉得有些法律会让这种做法变得相当棘手。

**问：**
关于你和埃隆之间的关系，你希望未来会如何发展？这种紧张感、这种互动，你希望它们会变成什么样？如果我们从现在往后看一、二、三年，你与他的个人关系，比如友谊、友好的竞争，以及所有这些互动，你希望它们会如何发展？

**奥特曼：** 我非常尊重埃隆，我希望在未来的岁月里，我们能够保持友好的关系。

**问：**
我也希望你们这个月就能建立友好的关系，一起竞争、一起获胜、一起探索这些想法。我猜你们之间肯定存在人才方面的竞争，但这应该是友好的竞争，只为建造炫酷的东西。埃隆在建造这类东西方面非常擅长，你也一样。

04 Sora：人们会以新的方式使用新工具

**奥特曼：**
说到炫酷的东西，Sora真的很吸引人，我有无数个问题想问。首先，它的确令人称奇，无论是在产品层面还是在哲学层面。那么让我从技术和哲学的角度问问你，你认为Sora相对于GPT-4这样的模型，对世界的理解是更多还是更少呢？当你训练这些补丁而不是语言标记时，世界模型会有什么不同吗？

**奥特曼：**
我觉得所有这些模型对世界模型的理解，实际上都比我们大多数人给予它们的赞誉要多。而且，因为它们也清楚地知道自己不理解或没有正确理解的东西，所以很容易看到它们的弱点，透过面纱看到真相，然后说，“啊，这都是假的。”但这并不是全部假的。只是其中一些部分有效，而另一些部分则无效。

我记得自己第一次看Sora生成视频时的场景，你会看到有人走过来，挡住画面几秒钟后又走开，而被遮挡的东西依旧在那儿。我当时想到，“哦，这还不错。”或者有些例子中，在一系列动作中，底层物理学的表现看起来如此出色，就像，“哦，这相当令人印象深刻。”但从根本上说，这些模型只是在变得越来越好，这种进步还将继续。从DALL-E
1到DALL-E 2到DALL-E 3再到Sora的发展轨迹来看，有很多人对每个版本都进行了批评，说它不能做这不能做那，但现在看看它们的表现如何。

**问：** 你刚才提到的遮挡问题，基本上就是模型对三维世界物理学的建模足够好，以捕捉这类情况。也许你可以告诉我，为了处理遮挡问题，世界模型需要做什么呢？

**奥特曼：** 我想说的是，它在处理遮挡方面做得非常好。如果我说它背后有一个很好的世界三维模型，那可能有点夸大其词了。

**问：** 但是，你能否仅通过这种二维训练数据的方法来实现这个目标呢？

**奥特曼：** 看起来这种方法将会取得令人惊讶的进展。我不想过多地猜测它将克服哪些限制，哪些不会，但是……

**问：** 你看到的这个系统有哪些有趣的限制？我知道你已经发布了一些有趣的例子。

**奥特曼：** 各种有趣的现象都有。比如说，在视频的随机位置，猫的身上突然多出了一个部位。你可以选择你想看的，但还有很多问题，还有很多弱点。

**问：** 你认为这是这种方法的一个根本缺陷吗？还是只需要更大的模型、更好的技术、更好或更多的数据，就能解决猫身上突然多出部位的问题？

**奥特曼：** 我认为这些都需要。我觉得这种方法在某种程度上与我们习惯的思考和学习方式有所不同。同时，我也相信随着规模的扩大，模型将会变得更好。

**问：** 你认为目前这种方法的某些限制是固有的，而不仅仅是因为我们还没有足够的数据或模型规模不够大？

**奥特曼：**
是的，我认为确实有一些固有的限制。但我也相信，随着时间的推移，随着技术的进步，我们将能够找到方法来克服这些限制。我认为这是一个不断发展的领域，我们仍在探索其边界。

**问：** 就像我提到的，大语言模型有 token，文本 token，而 Sora
则有视觉补丁。它把所有的视觉数据，包括各种不同的视频和图片，都转换成了补丁。训练过程可以说完全是自我监督的吗？还是会涉及到一些手动标注的工作？在整个过程中，人类发挥了怎样的作用？

**奥特曼：** 在不提及Sora具体培训方法的情况下，我们的工作中确实使用了大量的人类数据。

**问：** 但不是互联网规模的数据？所以是有很多人类参与，但“大量”这个词有点模糊。

**奥特曼：** 我认为在这种情况下，“大量”这个词是恰当的。

**问：** 我是个内向的人，要是和三个人一起出去，对我来说人就已经够多的了。要是四个人，那简直就是超负荷了。不过我猜你指的“大量”可能是比这……

**奥特曼：** 对，确实是有不止三个人在给这些模型做数据标注工作。

**问：**
好的，我明白了。但从根本上说，有大量的自我监督学习。就像你在技术报告中提到的是互联网规模的数据。那真是太美了，就像诗一样。也就是说，这些数据中有很多是没有人类标注的，它们是以自我监督的方式进行学习的，对吧？

**奥特曼：** 是的。

**问：** 那么问题是，互联网上有多少数据可以用于这种自我监督的学习方式，如果我们知道了自我监督的详细机制。你有没有考虑过公开更多这方面的细节？

**奥特曼：** 我们考虑过。你是说具体的数据来源吗？

**问：** 对，具体来说就是来源。因为非常有趣的是，大语言模型的魔法现在能否开始转向视觉数据，实现这一点需要做什么？

**奥特曼：** 我认为从表面上看，确实有可能，但我们还有很多工作要做。

**问：** 那么有什么危险呢？你为什么担心发布这个系统？它可能存在哪些危险？

**奥特曼：**
坦白地说，我认为在发布系统之前，我们必须要确保它足够安全和可靠。尽管自我监督学习的方法在处理大规模数据方面取得了很大进展，但我们仍然需要确保这些算法不会产生误导性的结果或用于不正当目的。例如，如果系统被用于生成深度伪造的内容或传播错误信息，那么这将对社会产生负面影响。我们试图成为一个负责任的公司，认真考虑我们向世界发布的内容，而不需要太多思考就能想到这项技术可能怎样走向不好的方向。

**问：** 这里有很多棘手的问题，你正在一个非常困难的领域里工作。你认为训练人工智能是否应该或在版权法下属于合理使用？

**奥特曼：**
我认为这个问题背后的真正问题是，那些创造有价值数据的人是否应该得到某种形式的补偿，因为他们的数据被利用了。我认为答案是肯定的。但我还不知道确切的答案是什么。人们提出了很多不同的建议。我们也尝试过一些不同的模式。但如果我像一个艺术家一样，首先我希望能够选择不让人用我的风格生成艺术作品。其次，如果他们确实用我的风格生成了艺术作品，我希望有与之相关的经济补偿。

**问：** 这就像从CD过渡到Napster再到Spotify一样。我们必须找到某种模式。

**奥特曼：** 模式会改变，但人们必须得到报酬。

**问：** 如果我们看得更远一点，为了激励人类继续创造炫酷的东西，应该有一些奖励机制。

**奥特曼：**
在我担心的所有事情中，人类会创造炫酷的东西，社会会找到某种方式来奖励这种创造性。这似乎是人类固有的特性。我们渴望创造，我们渴望证明自己的价值，我们想要以各种方式获得认同和地位。我认为，这些都不会消失。

**问：** 但回报可能不是金钱上的，而可能是名望或是其他炫酷的方式。

**奥特曼：** 也许在金融方面还有其他方式。我认为，我们可能还没有看到经济系统发展的最终模式。

**问：** 但艺术家和创作者们很担心。当他们看到Sora时，他们会惊呼，“我的天哪！”

**奥特曼：**
确实。当摄影技术出现时，艺术家们也非常担心，但后来摄影成为了一种新的艺术形式，人们通过拍照赚了很多钱。我认为类似的事情会不断发生。人们会以新的方式使用新工具。

**问：** 如果我们只看YouTube或其他类似平台，你认为在未来五年内，使用Sora等人工智能工具生成内容的比例会有多少？

**奥特曼：**
人们总是在谈论人工智能将在五年内取代多少工作岗位。他们通常的出发点是，有多少现有工作会被人工智能完全取代？但我的思考方式不是人工智能将完成多少工作，而是在未来一个时间范围内，人工智能将能完成多少种任务。所以，如果你考虑经济中所有的五秒钟、五分钟、五小时甚至可能是五天的任务，有多少是人工智能可以完成的？我认为这是一个更有趣、更有影响力、更重要的问题，比人工智能将取代多少工作更重要，因为人工智能只是一种工具，它将在越来越多的任务中以越来越高的复杂度和越来越长的时间范围内工作，让人们能够在更高的抽象层次上进行思考。因此，也许人们在工作中会变得更加高效。在某个时候，这不仅仅是量的变化，它还意味着质的变化——我们能在脑海中构思何种问题。我认为对于YouTube上的视频来说也是如此。许多视频，也许大多数视频，都会在生产过程中使用人工智能工具，但它们仍然会从根本上受到人的因素所影响，人们会完成其中的一部分工作。

**问：** 这真的非常有趣。我是说，我认为这有点吓人，但也很有趣。我倾向于认为人类喜欢观察其他人类，或者更接近于人类的生物……

**奥特曼：** 人类确实非常关心其他同类。

**问：** 是的。如果有比人类更酷、更好的东西，人类可能会关注两天，然后又会回到关心人类的事务上。

**奥特曼：** 这似乎是人类根深蒂固的本性。

**问：**
就像国际象棋一样，人们会说“哦，是的”，但现在大家还是继续玩国际象棋。我们忽略了一个视而不见却摆在眼前的事实，那就是相对于人工智能系统来说，人类在国际象棋方面的波安排下面真的很差。

**奥特曼：** 我们仍然举行赛跑比赛，尽管汽车的速度要快得多。有很多这样的例子。

**问：** 是的。也许它就像是Adobe套件里的某种工具，让制作视频变得更加容易，以及其他类似的事情。

**奥特曼：**
听着，我真的不喜欢面对镜头。如果我能找到一种不用面对镜头的方法，我会很高兴的。不幸的是，那还需要一段时间。生成面部图像的技术正在发展，但在视频格式中生成特定人物的面孔与生成通用面孔相比要复杂得多。

持续更新中......

