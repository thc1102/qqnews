# 奥特曼最新2.8万字专访回应一切：是马斯克选择分道扬镳 想掌控OpenAI

# 奥特曼最新2.8万字专访回应一切：是马斯克选择分道扬镳 想掌控OpenAI

腾讯科技讯 3月19日消息，据国外媒体报道，美国知名播客莱克斯·弗里德曼（Lex
Friedman）近期再次邀请人工智能领域的领军人物、OpenAI首席执行官山姆·奥特曼（Sam
Altman）进行专访。这次对话，奥特曼不仅深入剖析了OpenAI董事会近期的变动，还畅谈了首席科学家伊利亚·苏茨凯弗（Ilya
Sutskever）的未来动向、与埃隆·马斯克（Elon
Musk）之间的法律纷争，以及备受瞩目的文字转视频工具Sora、豪掷7万亿美元的芯片计划、即将推出的新一代大语言模型GPT-5，乃至通用人工智能（AGI）的远景规划等。

**划重点：**

  * _1_ 【OpenAI董事会风波】这段经历让奥特曼认识到，在追求通用人工智能（AGI）的过程中，可能会遇到一系列爆炸性的事件，这些事件虽然令人不安，但也为未来的挑战提供了宝贵的经验和教训。
  * _2_ 【首席科学家苏茨凯弗的未来动向】尽管他近期相对沉默，但奥特曼表示，苏茨凯弗一直在深入思考并确保OpenAI在追求AGI的过程中做出正确的决策。
  * _3_ 【与埃隆·马斯克的法律纷争】奥特曼表示不清楚马斯克的真实动机，但他认为OpenAI的初衷是作为一个人工智能研究实验室，逐步探索和发展，OpenAI的使命是将强大的技术免费提供给公众。
  * _4_ 【Sora和GPT-5】奥特曼对Sora的发展表示乐观，认为它在理解和模拟三维世界方面取得了令人印象深刻的进步，但也提到了Sora的局限性。GPT-5作为新一代大语言模型，虽然未在专访中详细讨论，但它预示着OpenAI在自然语言处理领域的持续进步。
  * _5_ 【通用人工智能的远景规划】OpenAI的“开放”不仅仅是关于开源，而是关于将技术作为公共福利提供给人们。
  * _6_ 【ChatGPT记忆能力】未来的AI助手不仅可以记住用户希望它记住的事情，还能从中吸取教训，并在未来提醒用户该怎么做或者要注意什么。
  * _7_ 【7万亿美元芯片项目】奥特曼否认自己发推文宣称要筹资7万亿美元，但他承认世界需要大量的算力支持，而能源供应、数据中心和供应链建设、制造足够芯片都存在巨大挑战。
  * _8_ 【没兴趣打造翻版谷歌】奥特曼对于打造比谷歌更好的搜索引擎没兴趣，认为这是将AI大材小用。他希望将大语言模型与搜索相结合，从而找到自己的商业模式。他还称自己讨厌广告。
  * _9_ 【AGI何时会出现】奥特曼预计，在2030年之前，或者可能比那更早，我们将拥有非常强大的AI系统。他称，AGI不是终点，它更接近是一个起点。

以下为此次专访实录全文：

01 OpenAI董事会风波

**问：** 请带我们回顾下从2023年11月16日周四开始的OpenAI董事会风波，也许是11月17日周五。

**奥特曼：**
那绝对是我一生中最痛苦的职业经历，充满了混乱、羞耻、沮丧以及其他一大堆负面的东西。不过，其中也不乏值得珍藏的美好瞬间。我希望自己当时能够保持冷静，不被过度的肾上腺素冲昏头脑，从而能够停下来细细品味那些宝贵的经历。

但当我看到那时候发的推文时，感觉这就像自己的悼词，记录着人们在那个特殊时期对我的赞美和支持。看到这些

推文，我深感欣慰，也感受到了身边人的爱与关心。真是太棒了！整个周末，尽管遭遇了一些不愉快的事情，但总体而言，我感受到的爱远远超过了恨。

尽管我不知道到底发生了什么，也不知道将要发生什么，这感觉真的很糟糕。确实有很多时候，我认为这将是人工智能安全有史以来最糟糕的事情之一。但我也很庆幸这一切发生得相对较早。我认为，在OpenAI成立和通用人工智能（AGI）诞生的过程中，注定会有一系列疯狂且具有爆炸性的事件发生。这些事件虽然令人不安，但也为我们提供了宝贵的经验和教训，为未来应对更多挑战做好了准备。

**问：** 但你自己有一种感觉，你会经历某种权力斗争？

![](https://inews.gtimg.com/news_bt/O2WOzXnQWEpM7Agn7bZzdT1J7LZz3BUgsT4XARYA6V9qkAA/1000)

**奥特曼：** 确实，通往通用人工智能的道路可能会涉及多方面的权力斗争。我希望是这样。

**问：**
所以，你必须要经历这些。正如您所言，我们需要深思熟虑如何构建董事会架构，如何有效组织，以及如何与合作伙伴沟通，力求在最大程度上减少权力斗争的发生。

**奥特曼：**
是的。回首过去，那段经历确实令人不悦，充满了艰难和痛苦。然而，当我们重新投入工作时，繁忙和紧张的节奏让我无暇过多沉湎于过去的情绪。在那之后的一个月，也许是45天里，我仿佛处于一种游离的状态，每天都像是在漂泊，思绪并不清晰。那时的我，情绪异常低落，仿佛被阴影笼罩。

**问：**
你对董事会审议过程的参与度和严谨性有了解吗？你能谈谈在这种情况下涉及的人际关系动态吗？是不是只是几次对话，然后事态突然激化，然后就有人提出“为什么我们不解雇山姆”之类的建议？

**奥特曼：**
我认为董事会成员总体上都是出于好意的人，我相信在那种压力环境下，人们感到时间紧迫或其他什么，人们会做出不那么明智的决定都可以理解。我认为OpenAI面临的挑战之一将是，我们需要有一个擅长在压力下运作的董事会和团队。

**问：** 你认为董事会的权力过大了吗？

**奥特曼：**
我认为董事会应该有很大的权力，但我们确实看到的一件事是，在大多数公司架构中，董事会通常要对股东负责。有时人们拥有超级投票权或其他什么。在这种情况下，我认为我们结构中的一个问题是，我们可能没有充分考虑到非营利组织董事会实际上掌握着很大的权力，除非你有其他规定。他们并不真正向任何人负责，基本上只对自己负责。这在某些方面是好的，但我们真正希望的是OpenAI的董事会能够对整个世界负责，尽管这在实践中可能很难实现。

**问：** 所以你们宣布组建新的董事会。

**奥特曼：** 是的。

**问：** 我想一开始有一个新的、规模较小的董事会，现在有一个新的最终董事会吗？

**奥特曼：** 还不是最终的董事会。我们增加了一些人，还会增加更多。

**问：** 在新的董事会中，有哪些是之前那个董事会中可能存在的问题，现在得到了解决？

![](https://inews.gtimg.com/news_bt/OoTbT7wJZb3hBpuZ0LYwZpoyHa_BeBVxCDWKLYvftZcdMAA/1000)

**奥特曼：**
原董事会在一年的时间里规模变小了。原本是九个人，后来减少到六个人，然后我们无法就新增成员达成一致。此外，我认为董事会也没有太多经验丰富的董事会成员，而OpenAI的很多新董事会成员在作为董事会成员方面更有经验。我认为这将有所帮助。

问：有人批评了新加入董事会的一些人。例如，我听到了很多人批评拉里·萨默斯（Larry
Summers）的加入。那么选择董事会成员的过程是怎样的？涉及哪些因素？

**奥特曼：** 选择布雷特·泰勒（Bret
Taylor）和萨默斯为董事会成员是在那个非常紧张的周末做出的决定，而那个周末真是就像坐过山车一样，给人一种大起大落的感觉。我们试图就新的董事会成员达成一致，这些成员既要让这里的执行团队感到满意，也要得到原董事会成员的认可。

实际上，萨默斯是原董事会成员推荐的人选之一。至于布雷特，我想在那个疯狂周末之前，我就提议过他，但他当时很忙，不想接受这份工作。之后，我们确实需要帮助，他才加入进来。我们也考虑了很多其他人选，但我觉得如果我回来的话，我需要更换新的董事会成员。我不认为我可以在同样的人员配置下再次与原董事会合作，尽管后来我们决定让亚当·德安吉洛（Adam
D'Angelo）留下。但我们考虑了各种配置，最终决定想要组建一个三人的董事会，并需要短时间内找到两名新的董事会成员。

所以那些决定确实是直接做出的，你必须在战场上迅速做出决定。那时你没有时间设计严格的流程。对于之后的新的董事会成员，以及我们还将要继续添加的新成员，我们有一些认为对董事会来说重要的标准，我们希望这些人具备的不同专长。与招聘一名高管不同，他只需要把一个角色做好，但对于董事会成员来说，他需要需要在治理和思考方面表现出全方位的能力。因此，布雷特说的一句话我很认同，那就是我们想要以成批的形式招聘董事会成员，而不是一次一个地招聘。我们正在考虑的是一群能够带来非营利组织专业知识、公司运营专业知识、良好的法律和治理专业知识的人，这是我们试图优化的目标。

**问：** 那么，对于单个董事会成员来说，技术素养重要吗？

**奥特曼：** 不是每个董事会成员都需要这类素养，但确实有一些人需要。这也是董事会职责一部分。

**问：**
关于OpenAI，人们可能不了解的有趣的一点是，我当然也不了解，那就是经营公司的所有细节。当人们想到董事会时，鉴于其中的戏剧化元素，他们可能首先会想到你。他们会想：如果你开发出AGI或你创造出一些极具影响力的产品，并成功将它们推向市场，你和董事会之间的对话会是什么样的？他们可能还会想：在那种情况下，应该有什么样的合适团队来进行决策和讨论？

**奥特曼：**
我认为，董事会中确实需要一些技术专家。同时，你需要一些能够思考“我们如何部署这项技术才能最大限度造福人类？”的人，还需要一些持有不同观点的人。我认为你我可能会犯的一个错误是，认为只有理解技术才是挑选董事会成员的重要标准，这当然是董事会应该讨论的一部分，但关于这项技术将如何影响社会和人们的生活，你也也同样希望能够在董事会中得到体现。

**问：** 你在考虑人选时，是更看重他们的过往经历，还是只是与他们交谈即可？

**奥特曼：** 过往经历很重要。当然，你们会进行很多交谈，但有些职位我完全不看重过往经历，只看他的上升势头，忽略掉Y轴的截距。

**问：** 谢谢。谢谢你为观众用数学的方式做出解释。

**奥特曼：** 对于董事会成员，我确实更看重Y轴截距。我认为过往经历中有一些深刻的东西可以说，经验是很难被替代的。

**问：** 你尝试将过往经历拟合为多项式函数还是指数函数？

**奥特曼：** 这个类比不太合适。

**问：**
好的。你之前提到了那个疯狂周末遭遇的一些低谷。对你来说，心理上还有哪些低谷？你有没有考虑过去亚马逊丛林里喝下亚胡阿斯卡（一种致幻剂），然后永远消失？

**奥特曼：**
那是一段非常糟糕的时期。当然，也有一些很棒的时刻。我的手机不断收到与我日常合作的人以及那些我已经十年没联系过的人发来的关怀信息。因为我当时正处于危机之中，因此没有太多时间去回应，没能充分感受到这份温暖，但这确实让人感到很棒。总的来说，那是一个非常痛苦的周末。就像是在公众面前进行的一场战斗，让我感到非常疲惫，比我预想的还要难受。我认为争斗通常都很累人，但这次真的特别疲惫。董事会是在周五下午做出决定的。我并没有得到太多答复，但我也认为，董事会有权这么做，所以我会稍微花点时间思考一下我接下来想做什么，但我也会努力从中找到隐藏的祝福。

我当时心想，我目前在OpenAI的工作，或者之前的工作，是经营一家规模相当大的公司。而我一直最喜欢的事情就是与研究者们一起工作。然后我就想，我可以非常专注地去做AGI的研究工作。我开始对这个想法感到兴奋。当时我甚至没有想到这一切都会化为泡影。那已经是周五下午了。

**问：** 所以你接受了这样的终结——

**奥特曼：**
非常快，真的非常快。我经历了一段短暂的迷茫和愤怒，但这种负面状态很快就过去了。到了周五晚上，我已经在和别人讨论下一步要做什么了，而且我对此感到很兴奋。我记得是周五晚上，我第一次从这里的执行团队那里听到消息，他们说：“嘿，我们要抗争到底。”然后我就去睡觉了，心里还是想着：我很兴奋，继续前进！

**问：** 你睡得好吗？

**奥特曼：** 根本就没怎么睡。奇怪的是，有一段四天半的时间，我睡得很少，吃得也不多，但还是精力充沛。战时你会学到一些关于肾上腺素的奇怪事情。

**问：** 所以你接受了这样的结局，OpenAI这个被你视为“孩子”的公司迎来了失败的一天。

**奥特曼：** 我对新的事物都感到兴奋。我心想：“行吧，这玩意儿确实疯了点，但管它呢！”

**问：** 这是一个很好的应对机制。

**奥特曼：**
然后到了周六早上，两位董事会成员打来电话说：“嘿，我们不想搅局。我们不想在这里储存太多价值。我们能谈谈你回来的事吗？”最初，我不想回去，但后来又仔细地想了想，我还是觉得，我真的很关心这里的人、合作伙伴和股东们。我爱这家公司。所以我对他们说：“好吧，但我有自己的条件。”然后在那个周末最痛苦的时候，我一直在反思，也被告知，不仅仅是我，整个团队都在想，我们试图努力维持OpenAI的稳定，而那时整个世界都在试图让它分崩离析，人们试图招募我们的人。

我们一直被告知：“好了，我们快要弄完了。我们快要完成了。我们只需要再多一点点时间。”这是一种非常混乱的状态，直到周日晚上，我几乎每隔几个小时就期待这种混乱能够结束，找到一种让我回去的方法，让事情恢复到原来的样子。但董事会随后任命了一位新的临时首席执行官，我当时就觉得，这感觉真的很糟糕。那是整个事件的最低谷时刻。我告诉你，这感觉很痛苦，但整个周末我感受到了很多关怀。除了周日晚上的那一瞬间，我不会用愤怒或仇恨来形容我的情绪，但我感受到了人们对我的爱。虽然痛苦，但那个周末的主导情绪是爱，而不是恨。

**问：** 你曾高度赞扬了米拉·穆拉蒂（Mira
Murati），你说她在你推文中提到的关键时刻给予了你特别帮助。也许我们可以稍微偏离一下主题。你欣赏穆拉蒂哪些品质？

**奥特曼：**
她在那个周末的混乱中做得很好，人们往往在危机时刻才会关注领导者的表现，无论是好是坏。但我真正欣赏这类领导者的一点是，他们在平凡的周二早上9点46分和日常繁琐工作中是如何表现的。他们如何出席会议，他们做决策的质量如何。这就是我所指的“静默时刻”。

**问：** 这意味着大部分工作都是在日复一日、一次次的会议中完成的。只要保持专注，并做出明智的决策即可。

**奥特曼：**
是的。你看，过去20分钟你想谈论的，我理解的，是那一个非常疯狂的周末，但那并不是OpenAI的真正意义所在。OpenAI真正重要的是过去的七年。

**问：** 嗯，确实如此。人类文明可不仅仅关于纳粹德国入侵苏联，尽管人们仍然关注这一点。

**奥特曼：** 这是完全可以理解的。

02 苏茨凯弗还有另一面

**问：**
它能帮助我们洞察人性，人性的极端，也许人类文明的某些成就和某些损害就是在这些时刻发生的。人类文明的某些毁坏和伟大成就得以显现，因此这非常具有启发性。下面，让我问你关于伊利亚·苏茨凯弗（Ilya
Sutskever）的事情。他是不是被劫持在一个秘密的核设施里充当人质？

**奥特曼：** 当然不是。

**问：** 那是被藏在普通的秘密设施里？

**奥特曼：** 也不是。

**问：** 这事儿都快成梗了。你认识伊利亚很久了，对吧？他显然卷入了董事会那场风波，还有那一大堆乱七八糟的事情。你现在和他关系怎么样？

**奥特曼：**
我依然喜欢伊利亚。我非常尊重他。关于他现在的计划，我无可奉告。那是他的问题，该由他来回答。但我真的很希望在我职业生涯的剩余时间里，我们能继续一起工作。他比我年轻一些，也许他还会再工作久一些。

**问：** 有一个搞笑梗说伊利亚好像看到了什么东西，比如他可能看到了通用人工智能，这让他内心充满了忧虑。伊利亚到底看到了什么？

**奥特曼：**
伊利亚从来没有看到通用人工智能。我们任何人都没有看到过。我们还没有开发出通用人工智能。不过，伊利亚身上有很多让我敬佩的品质，其中之一是他非常重视通用人工智能及其广泛的安全问题，包括这项技术将对社会产生的影响。随着我们继续取得重大进展，伊利亚是过去几年里我花最多时间讨论这将意味着什么的人之一，讨论我们需要做什么来确保我们做得正确，确保我们成功地完成使命。所以，虽然伊利亚没有看到通用人工智能，但他在思考并确保我们在这个过程中做得正确，这对人类来说是一份巨大贡献。

**问：**
我以前和他聊过很多次。我认为当他谈论技术时，总是进行这种长期思考。所以他不是在想一年后会怎么样，而是在想十年后的事情，只是从首要原则开始思考，比如“好吧，如果这项技术能够扩展开来，这里的根本要素是什么？它将走向何方？”
这也是他思考所有其他安全问题和所有类似问题的基础，这使得与他交谈非常有趣。你知道他为什么近来变得沉默了吗？他是在进行自我反思吗？

**奥特曼：** 再次强调下，我不想代表伊利亚发言。我觉得你应该问问他本人。他确实是一个习惯深入思考的人。我觉得伊利亚总是在以一种非常好的方式进行灵魂探索。

**问：** 对，没错。而且，他也很懂得沉默的力量。另外，我听说他有时也挺逗的，但我从没见过他那一面。

**奥特曼：** 那样的他真的很可爱。

**问：** 我从没见过逗比的伊利亚，但我也很期待看到那一面。

**奥特曼：** 我最近和他一起参加了一个晚宴，他当时正在和一只小狗玩，心情非常放松，那场景相当温馨！我当时就想，哇，这不是世界最常见的伊利亚。

**问：** 那么，就这整桩事情而言，你对董事会的架构满意吗？

**奥特曼：** 是的。

**问：** 关于这一切及其走向，你有什么看法？

**奥特曼：**
我对新组建的董事会感觉很满意。在OpenAI的架构方面，董事会的一项职责就是要审视并找出我们可以使其更加稳健的地方。我们原本想先安排新的董事会成员到位，但显然，在这个过程中，我们在结构方面学到了一个教训。我觉得我没有太多深刻的见解要说。这是一次疯狂、非常痛苦的经历。我觉得这是各种奇怪情况的完美风暴。这次经历让我预见到了未来的挑战：随着赌注的提高，我们将需要更加稳健的治理结构和流程，以及更加合适的人选。我很高兴这件事发生在我还年轻的时候，但经历它确实非常痛苦。

**问：** 这件事会让你在信任他人时变得更加犹豫吗？

**奥特曼：** 会。

**问：** 只是在个人层面吗？

**奥特曼**
：是的。我自认为是一个非常信任他人的人。我的人生哲学一直是不要过于担忧所有的偏执狂想，不要担心那些边缘情况。即便你稍微吃点亏，换来的是可以放下防备地生活。然而，这次经历对我来说太震撼了。我完全措手不及，它确实改变了我。我真的不喜欢这种感觉，但它确实改变了我对人的默认信任和对糟糕情况的应对方式。

**问：** 你得在这方面小心一点。你担心自己会变得过于愤世嫉俗吗？

**奥特曼：** 我不担心自己会变得过于愤世嫉俗。我认为自己与愤世嫉俗的人截然相反，但我担心自己会变得不那么容易信任他人。

**问：**
实际上，对于正在开发通用人工智能（AGI）的人来说，我不清楚应该选择信任模式还是不信任模式来行动才是最好的。这是一次有趣的旅程。但在结构方面，我更关注人性层面。你如何让自己身边围绕着既能构建出色事物，又能做出明智决策的人？因为随着你开始赚更多的钱，这个东西拥有更大影响力，周围的人们可能会变得越来越奇怪。

**奥特曼：**
关于董事会成员以及我应该持有的信任程度，或者我应该如何以不同的方式行事，你可以提出各种看法。但就这里的团队而言，我想你会给我非常高的评价。我对我每天一起工作的人们怀有巨大的感激、信任和尊重，我认为被这样的人们包围着真的非常重要。

03 关于马斯克的诉讼

**问：** 我们共同的朋友马斯克起诉了OpenAI。你认为他批评的实质问题是什么？他有多少批评能站得住脚？又有多少是错的？

**奥特曼：**
我真的不知道这究竟是怎么回事。我们一开始只是想成为一个人工智能研究实验室，对这项技术将如何发展一无所知。因为那是七八年前的事了，现在想回忆起当时的情况真的很难。那时大语言模型还没有成为人们关注的热门话题。我们还没想到要开发API或销售聊天机器人访问权限，也没有想过要将其产品化，我们只是想，“我们要努力做研究，但我们真的不知道要用它做什么。”我认为，对于许多全新的事物来说，你开始时总是摸着石头过河，做一些假设，其中大多数最后都被证明是错误的。

然后，我们逐渐明确需要采取不同的做法，并且需要更多的资金。所以我们说，“行吧，现在的结构并不适合这些。我们如何调整结构呢？”然后你只能一次次地修补它，最后你得到的东西至少看起来不禁让人皱眉。但我认为，我们是一步一步地逐渐走到这里的，每个阶段都做出了合理的决策。这并不意味着如果有机会回到过去，我会完全采取不同的做法，但问题是当时我们并没有先知。不管怎样，至于埃隆真正的动机是什么，我真的不清楚。

**问：** 就你所记得的，OpenAI在博客文章中是如何回应埃隆诉讼的？你能概括一下吗？

**奥特曼：**
哦，我们只是提到了埃隆提出的一系列观点。这是我们的陈述，或者这不是我们的陈述。这是对这件事发生过程的描述。我们尽量不带有个人情绪，只是陈述，“这就是历史。”

**问：**
我认为埃隆在这里对你刚才提到的一点有些误解，那就是你们当时的不确定性程度有多大。你们只是有几个人的研究团队，疯狂地谈论着AGI，而当时所有人都在嘲笑这个想法。

**奥特曼：** 不久之前，埃隆还在疯狂地谈论发射火箭，而当时人们也在嘲笑这个想法，所以我认为他会对这件事产生更多共鸣。

**问：** 我认为这里确实有一些个人因素，OpenAI和许多这里的杰出人才选择与埃隆分道扬镳，所以存在个人层面的因素——

**奥特曼：** 是埃隆选择分道扬镳。

**问：** 你能具体描述一下当时你们分道扬镳的情况吗？

**奥特曼：**
他认为OpenAI将会失败，他希望能够完全掌控并扭转局势。而我们则希望继续朝着现在OpenAI的方向前进。他还希望特斯拉能够开展AGI项目。在不同时期，他都想把OpenAI变成一家盈利公司，由他掌控，或者与特斯拉合并。但我们不想这么做，于是他决定离开，这其实挺好的。

**问：**
所以你的意思是，正如OpenAI博客文章中也提到的，他希望OpenAI能被特斯拉收购，或许是与微软的合作方式有点相似，或者说可能是一种更为戏剧化的形式。

**奥特曼：** 我记得当时的提议就是，是的，被特斯拉收购，并让特斯拉完全控制它。我很确定提议就是这个意思。

**问：**
那么，在当时的情况下，OpenAI这个词中的“open”对埃隆来说意味着什么？伊利亚在电子邮件交流和其他一些内容中谈到了这一点。在当时，这个词对你意味着什么？现在对你又意味着什么？

**奥特曼：**
如果能够重新来过，我会选择一个不同的名字。我认为OpenAI正在做的最重要的事情之一，就是将强大的技术免费地交到人们手中，作为一种公共福利。我们没有在免费版本上投放广告，也没有以其他方式将其商业化。我们只是认为这是我们的使命，即将越来越强大的工具免费交到人们手中，并让他们使用它们。我认为这种“开放”对我们的使命来说非常重要。我认为，如果你给人们提供绝佳的工具，并教他们如何使用，或者甚至不用教他们，他们自己也会摸索出来，然后让他们用这些工具共同构建一个不可思议的未来，这将是意义重大的。因此，如果我们能够继续向世界推出免费或低成本甚至免费的强大AI工具，这将极大地推进我们的使命。至于是否“开源”，我认为我们应该对一些东西开源，而对另一些则不开源。这往往会变成一场宗教般的信仰之争，很难保持中立，但我认为找到平衡点才是正确的答案。

**问：** 埃隆已经说过：“如果你们将公司名字改成CloseAI，我就放弃诉讼。”我意思是说，这会变成关于名字的梗吗？

**奥特曼：** 我觉得这反映了埃隆对这次诉讼的认真态度，我认为这样说真是令人惊讶。

**问：** 也许我说得不对，但我不认为这次诉讼在法律上是严肃的。更多的是为了表明对AGI未来和目前领先公司的看法。

**奥特曼：**
看，我的意思是，直到人们指出这有点虚伪之前，Grok并没有开源任何东西。然后，埃隆才宣布Grok本周将开源一些东西。我不认为开源与否是他真正关心的问题。

**问：**
好的，我们会谈谈开源与不开源的问题。我倒是觉得，也许批评竞争对手是件好事，只是稍微抱怨一下也无伤大雅。但这得是建立在友好竞争的基础上，比起来，我个人真是非常讨厌打官司。

**奥特曼：**
我认为整件事都不像一个建设者应该做的。我尊重埃隆。他是我们这个时代最伟大建设者之一。我知道他了解被仇恨者攻击的滋味，这让我感到格外难过，他居然也这样做。

**问：** 是的，他可以说是有史以来最伟大的建设者之一，甚至可能是有史以来最伟大的建设者。

**奥特曼：**
这让我感到难过。我认为这也让很多人感到难过。有很多人长期以来一直仰慕他。我在接受采访时也曾经说过，我怀念以前的埃隆，结果我收到了很多回复，他们都说：“你的话完全表达了我的心声。”

**问：**
我认为他应该直接获胜。他应该让X的Grok击败GPT，然后GPT再反过来击败Grok，这就是竞争，对每个人来说都是一件好事。但关于开源的问题，你认为有很多公司在探索这个概念吗？这很有趣。我觉得Meta在这方面出人意料地走在了前面，或者至少是在真正开源模型这场棋局中迈出了第一步。当然，他们开源的并不是最尖端的模型，不过他们开源了
Lama。谷歌也在考虑开放一个规模较小的版本。开源有什么优缺点？你自己有没有思考过这个问题？

**奥特曼：**
是的，我认为开源模型确实有其存在的必要，特别是那些人们可以在本地运行的小型模型，我认为这方面的需求非常大。我想将来会有一些开源模型，也会有一些闭源模型。在这方面，它与其他生态系统并无不同。

**问：** 我听了所有与这次诉讼和其他相关话题有关的播客。他们更关心的是从非营利组织转变为这种盈利上限结构的先例。这对其他初创公司来说会树立什么样的先例？

**奥特曼：** 我会强烈反对任何打算以非营利组织起步，后来再增加盈利部门的初创公司。我会强烈反对他们这样做。我不认为我们会在这里树立先例。

**问：** 以这种方式创业，初创公司是不可能节省很多钱的。

**奥特曼：** 没错。我觉得有些法律会让这种做法变得相当棘手。

**问：**
关于你和埃隆之间的关系，你希望未来会如何发展？这种紧张感、这种互动，你希望它们会变成什么样？如果我们从现在往后看一、二、三年，你与他的个人关系，比如友谊、友好的竞争，以及所有这些互动，你希望它们会如何发展？

**奥特曼：** 我非常尊重埃隆，我希望在未来的岁月里，我们能够保持友好的关系。

**问：**
我也希望你们这个月就能建立友好的关系，一起竞争、一起获胜、一起探索这些想法。我猜你们之间肯定存在人才方面的竞争，但这应该是友好的竞争，只为建造炫酷的东西。埃隆在建造这类东西方面非常擅长，你也一样。

04 Sora：人们会以新的方式使用新工具

**奥特曼：**
说到炫酷的东西，Sora真的很吸引人，我有无数个问题想问。首先，它的确令人称奇，无论是在产品层面还是在哲学层面。那么让我从技术和哲学的角度问问你，你认为Sora相对于GPT-4这样的模型，对世界的理解是更多还是更少呢？当你训练这些补丁而不是语言标记时，世界模型会有什么不同吗？

**奥特曼：**
我觉得所有这些模型对世界模型的理解，实际上都比我们大多数人给予它们的赞誉要多。而且，因为它们也清楚地知道自己不理解或没有正确理解的东西，所以很容易看到它们的弱点，透过面纱看到真相，然后说，“啊，这都是假的。”但这并不是全部假的。只是其中一些部分有效，而另一些部分则无效。

我记得自己第一次看Sora生成视频时的场景，你会看到有人走过来，挡住画面几秒钟后又走开，而被遮挡的东西依旧在那儿。我当时想到，“哦，这还不错。”或者有些例子中，在一系列动作中，底层物理学的表现看起来如此出色，就像，“哦，这相当令人印象深刻。”但从根本上说，这些模型只是在变得越来越好，这种进步还将继续。从DALL-E
1到DALL-E 2到DALL-E 3再到Sora的发展轨迹来看，有很多人对每个版本都进行了批评，说它不能做这不能做那，但现在看看它们的表现如何。

**问：** 你刚才提到的遮挡问题，基本上就是模型对三维世界物理学的建模足够好，以捕捉这类情况。也许你可以告诉我，为了处理遮挡问题，世界模型需要做什么呢？

**奥特曼：** 我想说的是，它在处理遮挡方面做得非常好。如果我说它背后有一个很好的世界三维模型，那可能有点夸大其词了。

**问：** 但是，你能否仅通过这种二维训练数据的方法来实现这个目标呢？

**奥特曼：** 看起来这种方法将会取得令人惊讶的进展。我不想过多地猜测它将克服哪些限制，哪些不会，但是……

**问：** 你看到的这个系统有哪些有趣的限制？我知道你已经发布了一些有趣的例子。

**奥特曼：** 各种有趣的现象都有。比如说，在视频的随机位置，猫的身上突然多出了一个部位。你可以选择你想看的，但还有很多问题，还有很多弱点。

**问：** 你认为这是这种方法的一个根本缺陷吗？还是只需要更大的模型、更好的技术、更好或更多的数据，就能解决猫身上突然多出部位的问题？

**奥特曼：** 我认为这些都需要。我觉得这种方法在某种程度上与我们习惯的思考和学习方式有所不同。同时，我也相信随着规模的扩大，模型将会变得更好。

**问：** 你认为目前这种方法的某些限制是固有的，而不仅仅是因为我们还没有足够的数据或模型规模不够大？

**奥特曼：**
是的，我认为确实有一些固有的限制。但我也相信，随着时间的推移，随着技术的进步，我们将能够找到方法来克服这些限制。我认为这是一个不断发展的领域，我们仍在探索其边界。

**问：** 就像我提到的，大语言模型有 token，文本 token，而 Sora
则有视觉补丁。它把所有的视觉数据，包括各种不同的视频和图片，都转换成了补丁。训练过程可以说完全是自我监督的吗？还是会涉及到一些手动标注的工作？在整个过程中，人类发挥了怎样的作用？

**奥特曼：** 在不提及Sora具体培训方法的情况下，我们的工作中确实使用了大量的人类数据。

**问：** 但不是互联网规模的数据？所以是有很多人类参与，但“大量”这个词有点模糊。

**奥特曼：** 我认为在这种情况下，“大量”这个词是恰当的。

**问：** 我是个内向的人，要是和三个人一起出去，对我来说人就已经够多的了。要是四个人，那简直就是超负荷了。不过我猜你指的“大量”可能是比这……

**奥特曼：** 对，确实是有不止三个人在给这些模型做数据标注工作。

**问：**
好的，我明白了。但从根本上说，有大量的自我监督学习。就像你在技术报告中提到的是互联网规模的数据。那真是太美了，就像诗一样。也就是说，这些数据中有很多是没有人类标注的，它们是以自我监督的方式进行学习的，对吧？

**奥特曼：** 是的。

**问：** 那么问题是，互联网上有多少数据可以用于这种自我监督的学习方式，如果我们知道了自我监督的详细机制。你有没有考虑过公开更多这方面的细节？

**奥特曼：** 我们考虑过。你是说具体的数据来源吗？

**问：** 对，具体来说就是来源。因为非常有趣的是，大语言模型的魔法现在能否开始转向视觉数据，实现这一点需要做什么？

**奥特曼：** 我认为从表面上看，确实有可能，但我们还有很多工作要做。

**问：** 那么有什么危险呢？你为什么担心发布这个系统？它可能存在哪些危险？

**奥特曼：**
坦白地说，我认为在发布系统之前，我们必须要确保它足够安全和可靠。尽管自我监督学习的方法在处理大规模数据方面取得了很大进展，但我们仍然需要确保这些算法不会产生误导性的结果或用于不正当目的。例如，如果系统被用于生成深度伪造的内容或传播错误信息，那么这将对社会产生负面影响。我们试图成为一个负责任的公司，认真考虑我们向世界发布的内容，而不需要太多思考就能想到这项技术可能怎样走向不好的方向。

**问：** 这里有很多棘手的问题，你正在一个非常困难的领域里工作。你认为训练人工智能是否应该或在版权法下属于合理使用？

**奥特曼：**
我认为这个问题背后的真正问题是，那些创造有价值数据的人是否应该得到某种形式的补偿，因为他们的数据被利用了。我认为答案是肯定的。但我还不知道确切的答案是什么。人们提出了很多不同的建议。我们也尝试过一些不同的模式。但如果我像一个艺术家一样，首先我希望能够选择不让人用我的风格生成艺术作品。其次，如果他们确实用我的风格生成了艺术作品，我希望有与之相关的经济补偿。

**问：** 这就像从CD过渡到Napster再到Spotify一样。我们必须找到某种模式。

**奥特曼：** 模式会改变，但人们必须得到报酬。

**问：** 如果我们看得更远一点，为了激励人类继续创造炫酷的东西，应该有一些奖励机制。

**奥特曼：**
在我担心的所有事情中，人类会创造炫酷的东西，社会会找到某种方式来奖励这种创造性。这似乎是人类固有的特性。我们渴望创造，我们渴望证明自己的价值，我们想要以各种方式获得认同和地位。我认为，这些都不会消失。

**问：** 但回报可能不是金钱上的，而可能是名望或是其他炫酷的方式。

**奥特曼：** 也许在金融方面还有其他方式。我认为，我们可能还没有看到经济系统发展的最终模式。

**问：** 但艺术家和创作者们很担心。当他们看到Sora时，他们会惊呼，“我的天哪！”

**奥特曼：**
确实。当摄影技术出现时，艺术家们也非常担心，但后来摄影成为了一种新的艺术形式，人们通过拍照赚了很多钱。我认为类似的事情会不断发生。人们会以新的方式使用新工具。

**问：** 如果我们只看YouTube或其他类似平台，你认为在未来五年内，使用Sora等人工智能工具生成内容的比例会有多少？

**奥特曼：**
人们总是在谈论人工智能将在五年内取代多少工作岗位。他们通常的出发点是，有多少现有工作会被人工智能完全取代？但我的思考方式不是人工智能将完成多少工作，而是在未来一个时间范围内，人工智能将能完成多少种任务。所以，如果你考虑经济中所有的五秒钟、五分钟、五小时甚至可能是五天的任务，有多少是人工智能可以完成的？我认为这是一个更有趣、更有影响力、更重要的问题，比人工智能将取代多少工作更重要，因为人工智能只是一种工具，它将在越来越多的任务中以越来越高的复杂度和越来越长的时间范围内工作，让人们能够在更高的抽象层次上进行思考。因此，也许人们在工作中会变得更加高效。在某个时候，这不仅仅是量的变化，它还意味着质的变化——我们能在脑海中构思何种问题。我认为对于YouTube上的视频来说也是如此。许多视频，也许大多数视频，都会在生产过程中使用人工智能工具，但它们仍然会从根本上受到人的因素所影响，人们会完成其中的一部分工作。

**问：** 这真的非常有趣。我是说，我认为这有点吓人，但也很有趣。我倾向于认为人类喜欢观察其他人类，或者更接近于人类的生物……

**奥特曼：** 人类确实非常关心其他同类。

**问：** 是的。如果有比人类更酷、更好的东西，人类可能会关注两天，然后又会回到关心人类的事务上。

**奥特曼：** 这似乎是人类根深蒂固的本性。

**问：**
就像国际象棋一样，人们会说“哦，是的”，但现在大家还是继续玩国际象棋。我们忽略了一个视而不见却摆在眼前的事实，那就是相对于人工智能系统来说，人类在国际象棋方面的波安排下面真的很差。

**奥特曼：** 我们仍然举行赛跑比赛，尽管汽车的速度要快得多。有很多这样的例子。

**问：** 是的。也许它就像是Adobe套件里的某种工具，让制作视频变得更加容易，以及其他类似的事情。

**奥特曼：**
听着，我真的不喜欢面对镜头。如果我能找到一种不用面对镜头的方法，我会很高兴的。不幸的是，那还需要一段时间。生成面部图像的技术正在发展，但在视频格式中生成特定人物的面孔与生成通用面孔相比要复杂得多。

05 GPT-4：我对它有点失望

**问：** 我想问你些关于GPT-4的问题。有很多问题要问。首先，它同样令人惊叹。回首过去，GPT-4在塑造
ChatGPT的过程中，可能被视为与GPT-3以及GPT-5同样关键的历史性时刻。

**奥特曼：** 也许GPT-5会是关键时刻。我不知道。很难说未来会如何。

**问：**
我们永远不会知道。这就是未来的恼人之处，很难预测。但对我来说，回顾过去，GPT-4，ChatGPT真的令人印象深刻，在历史上都有重要意义。所以请允许我问，GPT-4和GPT-4
Turbo给你带来的最令人印象深刻的能力是什么？

**奥特曼：** 我觉得它有点令人失望。

**问：** 这种观点很常见，毕竟人类总是习惯了一个很棒的东西后就会觉得它变得平常了。

**奥特曼：**
不，我认为这确实是一件令人惊奇的事情，但相对于我们需要达到的目标和我相信我们将达到的目标来说，在GPT-3的时代，人们会说，“哦，这太棒了。这简直是技术的奇迹。”确实如此。但现在我们有了GPT-4，再回头看GPT-3，你会觉得它简直糟糕透顶。我预计GPT-5与GPT-4之间的差距将与GPT-4与GPT-3之间的差距一样大，而且我认为我们的职责就是提前几年预见未来，并记住我们现在拥有的工具在未来回头看时会显得有些不尽如人意，这样我们才能确保未来会变得更好。

**问：** GPT-4在哪些方面最令人失望？

**奥特曼：** 它最擅长做什么事情？

**问：** 对，它能做的最好的事情是什么？这些最好的事情存在哪些局限性，让你觉得它令人失望，从而激发你对未来的灵感和希望？

**奥特曼：**
我最近更多地将GPT-4用作一种头脑风暴伙伴。它有一些令人惊叹的东西。当人们谈论它的功能时，他们会说，“哦，它帮助我更有效地编写代码。它帮助我更快更好地写作。它帮助我从这种语言翻译到另一种语言。”所有这些事情都令人惊叹，但GPT-4也能充当创意头脑风暴伙伴，比如当“我需要为这个东西想一个名字。我需要以不同的方式思考这个问题。我不知道该怎么办”时，我认为这让我看到了自己期待已久的东西，希望将来能看到更多类似的场景。

你可以看到的另一个非常小的迹象是，当我需要完成更长期的任务时，将某件事情分解成多个步骤，也许GPT-4能执行其中的一些步骤，比如搜索互联网，编写代码，无论什么，然后再将它们组合在一起。当它能在这个过程中发挥作用时，虽然不是很常见，但却非常神奇。

**问：** 与人类不断互动，对我来说非常有帮助。这是什么意思？

**奥特曼：** 通过与人类的互动，当它可以独立解决一个包含10个步骤的问题时，这样的互动就会变得更加密集。尽管有时它并不经常奏效。

**问：** 增加多个抽象层次，还是说你只是指按顺序进行？

**奥特曼：**
两者都很重要，既要将问题分解，也要在不同的抽象层次上做一些事情来将它们重新组合在一起。你看，我不想低估GPT-4的能力，但我也不想过分夸大它。我认为，我们正处于一个指数曲线上，不久之后，我们会像现在回望
GPT-3 一样去回顾 GPT-4。

**问：** 也就是说，ChatGPT是一个转折点，外界开始相信有一种上升趋势，而不仅仅是在OpenAI内部。

**奥特曼：**
当然。从这个意义上说，我确实认为这将是一个转折点，世界上很多人将从怀疑者转变为信徒。这更多是关于ChatGPT界面的。而说到界面和产品，我也指的是模型训练后的调整，以及我们如何调整它以帮助你，以及如何使用它，而不仅仅是模型本身。

**问：** 这两者中哪一个更重要？是底层模型，还是RLHF（Reinforcement Learning from Human
Feedback，人类反馈强化学习）或类似的东西，它们都在调优过程中起着关键作用，使模型对人类更具吸引力，对人类更有效和有用。

**奥特曼：**
我认为它们都很重要，但RLHF，也就是训练后的那个步骤，以及我们在基础模型之上所做的那些额外工作，从计算的角度来看，尽管这是大量的工作，但这确实很重要，更不用说我们围绕它构建的产品了。从某种意义上说，我们必须同时做好这两件事：我们必须发明底层技术，然后弄清楚如何将其变成人们会喜欢的产品，这不仅仅是关于实际产品的工作，还涉及到一个完全不同的阶段——怎样让产品与用户的需求保持一致，并真正发挥出它的用途。

**问：** 在众多用户同时使用这项技术的时候，你是如何让它发挥规模化效应的。所有这些方面，都得仔细斟酌。

**奥特曼：**
那是已知的难题。我们知道我们必须扩大规模。我们必须去做两件以前从未做过的事情，我认为这两件事都是相当重要的成就，然后还有很多其他公司以前必须做的事情，比如扩大规模。

**问：** 在GPT-4到GPT-4 Turbo之间，上下文窗口从8K tokens增加到128K tokens，这两者之间又怎样的区别？

**奥特曼：** 多数情况下，大多数人并不总是需要128K
tokens这么长的上下文。然而，如果我们展望未来，我们会发现将来会有数十亿长度的上下文。你可以输入你所有的信息和历史记录，模型会越来越了解你，那将是非常棒的。但目前来看，人们使用这些模型的方式并不是这样。人们有时会发布论文或在代码库中大量增加代码，但大多数时候，模型的使用并没有用到长上下文。

**问：**
我喜欢这样的感觉，就像你的“我有一个梦想”演讲。将来，你会被依据你性格的全貌或是你一生的总体来评价。那很有趣。那么，你所希望的是更全面、更长的上下文。

**奥特曼：** 我曾经在网上看过一个片段，我可能记错了数字，但大致是比尔·盖茨（Bill
Gates）谈论早期计算机的内存容量大小，可能是64K，也可能是640K，大概是这样的数字。那时候，大部分内存都被用于屏幕缓冲区。他看起来似乎无法真正理解，为何将来世界上的计算机会需要几个GB甚至TB的内存。不过，你总是需要跟上技术发展的指数增长曲线，我们总会发现如何使用更先进技术的方法。所以，我现在真的无法想象，有一天上下文链接会增长到数十亿是什么感觉。它们可能不会真的达到那个数字，但在效果上可能会有那种感觉。不过我知道，一旦我们拥有这类技术，就真的不再想回到过去了。

**问：**
未来会有某种突破，让人感觉到像是拥有无限上下文一样。但即便是120K，老实说，我还没有尝试将它推到那种极限，可能需要输入整本书或整篇论文。你见过的GPT-4的一些有趣用例是什么？

**奥特曼：**
我发现最有趣的是，人们将它作为任何知识型工作任务的默认起点，这主要是在年轻人中。它能够做很多事情，而且做得相当好。你可以使用GPT-4来帮助你编写代码，进行搜索，或者编辑论文。对我来说，最有趣的是那些直接以此为他们工作流程开端的人。

**问：**
我也是。我用它来作为阅读书籍的伙伴。它帮助我思考，尤其是我阅读经典名著的时候。我发现它在涵盖广泛主题的方面往往比维基百科还要好。它似乎更平衡，更细致入微。也许这是我的感觉，但它激发我思考得更深入，比维基百科的文章还要深入。我不太确定这是为什么。

你刚才也提到了这种协作，我不确定魔力在哪里。但当我开始使用GPT进行知识型任务时，我通常会担心之后需要进行的事实核查，比如检查它是否编造了虚假内容。你是如何发现GPT能够提出听起来非常令人信服但实际上是虚假的内容的？你如何确保它的真实性？

**奥特曼：** 这显然是我们非常关注的一个领域。我认为随着后续版本的推出，这方面会得到很大的改善，但我们必须继续努力，今年我们不可能完全解决所有问题。

**问：** 令人担忧的是，随着它的不断改进，你可能会开始越来越少地进行事实核查，对吧？

奥特曼：我对此有个矛盾的看法。我认为人们在使用技术时比我们常常认为的要精明得多。人们似乎真的明白GPT这类模型有时会出现幻觉。如果在执行关键任务，你必须对其回复进行核实。

06 记忆与隐私

**问：**
这个问题涉及到人类文明的更高层面，我很期待对此进行探讨。这正是我们应该更多去庆祝的领域。你们赋予了ChatGPT记忆能力，让它可以回顾之前的对话，也可以关闭记忆功能。有时我真希望自己也能这样做，根据需要随时开启或关闭记忆。虽然酒精有时能达到这种效果，但显然不是最理想的方式。你在尝试记住对话和不记住对话的过程中，有什么发现吗？

**奥特曼：**
我们在这一领域的探索还处于非常初级的阶段，但我认为人们想要的，或者至少是我自己想要的是，一个能够逐渐了解我并对我越来越有用的模型。这是我们的初步探索，我认为还有很多其他工作要做，但这是我们希望努力的方向。你希望使用一个模型，或者在使用系统的过程中使用多个模型，随着时间的推移，这些模型会变得越来越好。

**问：**
这个问题有多难解决？因为现在它更像是记住一些小的事实和偏好等等。那么关于记忆呢？你不希望GPT记住你在去年11月经历的所有事情和所有的戏剧性事件，然后你可以……

**奥特曼：**
我不仅希望它记住那些事情，我还希望它能从中吸取教训，并在未来提醒我该怎么做或者要注意什么。我们在生活中都会从经历中获得不同程度的成长，我也希望我的人工智能助手能从这些经历中学习和成长。所以，如果我们回溯并想象一个拥有万亿上下文长度的模型可用，如果我能把自己一生中与任何人的所有对话都放进去，把所有电子邮件的输入输出都放进去，每次我问问题时都能在上下文中找到所有的输入输出，那将会非常了不起。

**问：** 是的，我认为那将会非常棒。但有时人们听到这些会担心隐私问题。对于人工智能更有效地整合你的所有经历和数据，并给你建议这一方面，你怎么看？

**奥特曼：**
我认为正确的答案是给用户选择的权力。任何我不想让我的人工智能助手记住的事情，我都希望能把它删除。如果我不想记住任何事情，我也希望可以忘记。在关于我们自己的人工智能在隐私和实用性之间的权衡上，你和我可能有不同的看法，这完全可以理解。但我认为答案就是让用户轻松做出选择。

**问：**
但公司应该对用户选择给予高度的透明度，因为过去有些公司在收集用户数据时态度含糊其辞，好像他们可以默认收集你的所有数据。他们会说：“嗯，我们收集你的所有数据是理所当然的。我们用这些数据来做广告等，都是出于好意。”
但对于其中的细节却缺乏透明度。

**奥特曼：**
你说得完全对。就像之前提到的我在回避去年11月份的事情。我认为那是一件非常痛苦的事情，它让我长时间陷入恍惚。毫无疑问，那段时间最艰难的工作就是坚持工作，因为我必须试着回到这里，在震惊和痛苦中把碎片拼凑起来，而没有人真正关心这一点。我的团队确实给了我很大的宽容，我并没有像往常一样全力工作。但有一段时间，我不得不同时做这两件事，这真的很难。但有一天早上我醒来，想到：“这是一件发生在我身上的可怕事情。我觉得我可以永远像个受害者一样，告诉自己这是我一生中触及的最重要的工作，我必须回过神来继续它。”没错，这并不意味着我已经把它压抑下去了，因为有时我半夜醒来还会想到这件事。但我确实觉得自己有义务继续向前走。

**问：**
关于GPT能够做什么和不能做什么，你的直觉非常有趣。GPT在生成每个token时大约分配相同数量的计算资源。那么，在这种方法中，是否有空间进行更慢、更连贯的思考呢？

**奥特曼：** 我认为将有一种新的思考范式。

**问：** 这种思考方式在架构上会与我们现在看到的LLM（大语言模型）相似吗？它是在LLM的基础上增加的一层吗？

**奥特曼：**
我可以想象出许多实现这种想法的方法。但我认为这不如你之前的问题重要，那就是我们是否需要一种更慢的思考方式，其中答案不必立即给出……我想在精神层面上，你可能会希望人工智能能够更深入地思考一个更难的问题，并更快地回答一个更简单的问题。我认为这才是重要的。

**问：** 这让人想到人类的思考方式，我们有能力进行深入思考，那么人工智能也应该能够做到吗？这是错误的直觉吗？

**奥特曼：** 我认为这是一种合理的直觉。

**问：** 有趣。那么，当GPT发展到GPT-7时，它不可能立即就能给出“费马定理的证明”？

**奥特曼：**
在我看来，你希望能够对更难的问题分配更多的计算资源。如果你问一个这样的系统，“证明费马定理”，与问“今天是几号？”相比，除非它已经知道并记住了证明的答案，否则如果它需要自己去解决这个问题，那么这将需要更多的计算资源。

**问：** 但它能否看起来像一个大语言模型在与自己对话呢？

**奥特曼：** 可能。我是说，你可以想象有很多可行的方法。至于正确或最佳的方式是什么，我们目前还不知道。

07 神秘Q*：仍没有飞跃的迹象

**问：** 这让我想到了神秘的Q*项目。这个项目究竟是什么？

**奥特曼：**
OpenAI在保密方面做得并不好。如果我们能在这方面做得好一些，那将是一件好事。我们一直受到很多泄密问题的困扰，如果能拥有某种保密能力，那将是很不错的。

**问：** 你能谈谈Q*是什么吗？

**奥特曼：** 我们现在还不准备谈论这个话题。

**问：** 但这样的回答意味着有些东西可以谈论，这真的很神秘。

**奥特曼：**
我们的研究涉及各种领域。我们之前已经说过，我们认为在这些系统中实现更好的推理是一个重要的研究方向。我们还没有找到突破的方法，但我们对此非常感兴趣。

**问：** Q*或其他方面，会不会出现类似于ChatGPT的飞跃时刻？

**奥特曼：** 这是问题问得好。我怎么看待这个问题？这很有趣。对我来说，这看起来都是连续的发展过程。

**问：**
没错。你提到的主题似乎是，我们基本上是在逐渐攀登一个指数级的曲线。但从外部观察者的角度来看，我看着就觉得有飞跃的时刻。但对你来说，并没有这样的感觉吗？

**奥特曼：**
我一直在想，我们采用这种部署方式（我们称之为迭代部署），而不是秘密开发直到GPT-5，我们决定公开讨论GPT-1、GPT-2、GPT-3和GPT-4。这样做的原因部分在于，我认为人工智能和意外之间并不相容。而且，无论是世界、人类、机构，或者你愿意怎么称呼它们，它们都需要时间去适应和反思这些问题。我认为OpenAI做得最好的事情之一就是采取这种策略，让世界关注我们的进展，认真对待AGI，思考在我们被迫匆忙做出决定之前，我们想要构建什么样的系统、结构以及治理方式。

我认为这真的很好。但像你和其他人仍然觉得有飞跃的感觉，让我想到我们可能应该更多以渐进的方式发布我们的产品。我不知道这意味着什么，我还没有准备好答案，但我们的目标绝不是让世界感到震惊。相反，我们想要的是平稳过渡。这就是我们努力的方向，也是我们的既定策略，但我感觉我们似乎没有实现目标。也许我们应该考虑以不同的方式发布GPT-5或类似产品。

**问：** 是的，比如4.71，4.72这样的版本？但人们通常喜欢庆祝特别的日子，比如庆祝生日。我不知道你是否了解人类，但他们确实喜欢这些里程碑式的事情。

**奥特曼：**
我确实了解一些人类，人们确实喜欢里程碑。我完全理解这一点。我想我们自己也喜欢里程碑，宣布在这个领域取得胜利并开始下一个项目确实很有趣。但的确，我觉得我们在某些方面可能理解有误。

08 GPT-5发布时间待定

**问：** GPT-5什么时候发布？

**奥特曼：** 我不知道，这是实话。但我们今年会发布一个令人惊叹的新模型，只是我不知道我们会叫它什么。

**问：** 这就引出了一个问题，你们应该如何发布这个新模型呢？

**奥特曼：**
在接下来的几个月里，我们会发布许多不同的东西。我觉得这会很酷。在我们谈论一个类似GPT-5的模型之前，无论是否这样命名，或者比你期望的GPT-5好一点或差一点，我认为我们还有很多其他重要的事情要先发布。

**问：**
我不知道应该对GPT-5有什么样的期待。你的说法让我既感到紧张又兴奋。对于最终无论它会被命名为什么，我们就暂时称它为GPT-5吧，它需要克服的一些最大挑战和瓶颈是什么？只是好奇问一下：是关于计算方面的问题吗？还是技术方面的问题？

**奥特曼：**
这些挑战总是多方面的。你知道，最大的突破点是什么？是一台更大的计算机吗？是一个新的秘密吗？还是其他什么东西？这些都是需要综合考虑的。OpenAI真正做得好的事情是，这其实是伊利亚的一个原创观点，我可能会说得不太准确，但大致意思是，“我们将200个中等规模的东西相乘，形成一个巨大的东西。”

**问：** 所以这里有一种持续的分布式创新过程？

**奥特曼** ：是的。尤其是在技术层面上。

**问：** 在涉及到各个层面的细节时，你这是如何与不同的、分散的团队合作的？这些中等规模的东西是如何成为一个完整的巨型变形金刚的呢？

**奥特曼：**
有些人需要考虑如何将整个事情整合在一起，但也有很多人会努力将大局记在脑子里。从总体上来说，你当然不可能知道每个部分的具体工作原理，但我通常认为，有时把视野放大，看看全局是很有用的。我认为这不仅适用于解决技术问题，对商业创新同样有效。但事情会以令人意想不到的方式结合在一起，即使大部分时间你都在某个领域的细节中操作，对全局的理解也会带来令人惊讶的见解。事实上，我有一个秘诀，那就是对科技行业所有或大多数前沿领域都有很好的了解。有时，我可以看到这些联系或新的可能性，如果我只深入探索一个领域，我就不会有这个想法，因为我缺少全局数据。但我现在真的没有那样的视角了，我现在深入某一个特定领域。但我知道，拥有全局视角是一件有价值的事情。

09 7万亿美元大项目

**问：** 谈到从宏观角度看问题，让我们再扩大些范围，比如你曾发推文说需要7万亿美元。

**奥特曼：** 我没有发过那样的推文，也从来没有说过“我们正在筹集7万亿美元”之类的话。

**问：** 哦，那是别人说的？但你说过，“管他的，或许是 8 万亿”，是这样吗？

**奥特曼：**
不，我没有说过那个。我确实认为算力将称为未来的货币。我认为它可能会成为世界上最珍贵的商品，而且我认为我们应该大力投资以制造更多的算力。我认为算力市场将是一个不同寻常的市场。人们会想到手机芯片市场或其他类似的市场。你可以想象下，全世界有80亿人，也许70亿人拥有手机，也许是60亿，我们就这么假设吧。他们每两年升级一次，所以每年的市场需求就是30亿部智能手机的系统级芯片。但如果你制造了300亿套，你也不可能卖出10倍的手机，因为大多数人只有一部手机。

但算力是不同的。智能将更像能源或其他类似的东西，我认为唯一有意义讨论的是，在价格X下，世界将用掉多少算力。而在价格Y下，世界将消耗多少算力。因为如果算力真的很便宜，我会让它整天读取我的电子邮件，给我提建议，关于我可能需要思考或处理的事情，甚至是尝试治疗癌症。而如果计算资源真的很贵，也许我只会在尝试治疗癌症时才使用它。

所以我认为世界将需要大量的算力。而在这个过程中，有许多难点。能源供应是最棘手的部分，建造数据中心和供应链也同样充满挑战。当然，制造足够的芯片也很难。但看起来，这正是事情发展的方向。我们将需要大量的算力，目前来说，这种规模是难以想象的。

**问：** 你如何解决能源问题？核能？核聚变？你认为核聚变是50年后的事情，还是10年后就能实现？

**奥特曼：** 我相信核能的潜力。但我认为，何时实现核聚变依然很难预测。

**问：** 那么，谁会解决这个问题呢？

**奥特曼：**
我认为Helion公司做得最好，我对当前的核聚变竞赛感到挺兴奋。我认为核裂变也非常惊人，我希望全世界都能重新接受它。核裂变的历史发展让我感到非常遗憾，我希望我们能以有意义的方式重新利用它。

**问：** 所以对你来说，核裂变是个解决方案吗？就像我们目前所拥有的核反应堆一样？而且很多人因为切尔诺贝利等核泄漏事故而感到害怕，对吧？

**奥特曼：** 我认为我们应该制造新的核反应堆。我认为这个行业停滞不前真是太可惜了。

**问：**
你认为“群体性歇斯底里”能解释这种停滞现象吗？我不知道你是否了解人类，但这就是其中一个危险。核裂变面临的安全威胁之一就是人类对此的深度恐惧。这是我们必须将其纳入考虑的因素之一，所以我们必须赢得人们的信任，并展示它的安全性。

**奥特曼：** 我对人工智能也有这样的担忧。我认为人工智能的某些事情上会犯下大错。虽然我不确定自己最终被人工智能杀死的概率有多大，但肯定不是零。

**问：**
你如何降低这种戏剧性风险的影响？我已经开始听到一些传闻了，因为我和各个政治派别的人都有交谈，听到一些传闻说人工智能将会被政治化。我真的非常担心这一点，因为如果这样，可能就会出现右翼反对人工智能，而左翼支持人工智能的情况。然后这种戏剧性效果就可以被充分利用。我们该如何对抗这种趋势呢？

**奥特曼：**
我觉得人工智能确实会陷入左右派系之争。我不知道这具体会是什么样子，但不幸的是，任何具有影响力的事物似乎都会如此。我所说的戏剧性风险更多是指，我相信人工智能将会带来的好处远远多于坏处，但它确实会有一些坏处。例如，死于空气污染的人数远多于死于核泄露事故的人数，但大多数人更担心住在核反应堆附近而不是煤炭工厂附近。然而，我们人类的天性就是，尽管我们需要面对许多不同种类的风险，但那些能够构成电影高潮情节的风险在我们心中的分量却远大于那些长期、缓慢累积但同样严重的风险。

**问：**
这就是为什么真相很重要的原因。我希望人工智能能帮助我们看清事物的本质，保持平衡，弄清楚世界上事物的实际风险和真正危险。在人工智能领域的竞争中，与谷歌、Meta、xAI等公司竞争，各有什么优劣之处呢？

**奥特曼：**
对于这个问题，我想我有一个相对直接的答案，虽然以后可能会想到更多的细节，但好处似乎很明显，那就是我们能得到更好、更快、更便宜的产品和创新，这些都是竞争带来的好处。而缺点在于，如果我们不小心，可能会导致一场让令人担忧的军备竞赛。

**问：** 你是否感觉到这种军备竞赛带来的压力，就像在某些方面产生的负面影响一样？

**奥特曼：**
当然，在某些方面肯定是有的。我们花了很多时间讨论需要优先考虑安全性。我一直以来都在说，你可以把AGI的开始时间想象成一个四象限图，包括慢启动和快启动，以及长期和短期的时间线。我认为短期、慢启动是最安全的象限，也是我最希望我们所处的象限。但我确实想确保我们实现的是慢启动。

**问：** 我对与埃隆的突感到有些困扰的部分原因是，它导致了安全方面的孤立而非合作。这往往导致事情变得封闭而不是开放，也许在模型上开源会是个解决办法。

**奥特曼：** 埃隆至少说过他非常关心人工智能的安全性，并且对此感到非常担忧。我猜他应该不会在不安全的情况下进行竞赛。

**问：** 埃隆以关心人类的命运著称，而人类是从合作中受益是，所以激励和动机之间总是存在紧张关系。最后，我确实希望人类能够胜出。

**奥特曼：** 我在想，有人前几天提醒我，在埃隆超越杰夫·贝索斯（Jeff
Bezos）成为世界首富的那一天，他发推文向贝索斯展示了一枚银牌。我真心希望，以后能少看到这样的闹剧。埃隆的某些特质的确很了不起，我非常尊重他。我认为我们需要他，我们都应该支持他，并需要他在接下来的阶段中扮演好领导者的角色。

10 谷歌及其Gemini

**问：**
谷歌凭借搜索功能在过去20年里一直占据主导地位。可以说，从全市范围内获取信息的方式以及人们如何互动等方面来看，谷歌都发挥了关键作用。但令谷歌乃至整个行业都感到紧张的是，人们将如何获取信息？就像你说的，人们将GPT作为出发点。那么OpenAI是否会真正接手谷歌20年前开始的事情，即我们如何获取信息？

**奥特曼：**
我觉得这很无聊。我的意思是，如果问题是我们能否构建一个比谷歌更好的搜索引擎，那么当然可以，人们应该使用更好的产品，但我认为这低估了这项技术的潜力。谷歌给你展示10个蓝色链接，当然先是13个广告然后才是10个蓝色链接，这只是获取信息的一种方式。但令我兴奋的事情不是我们可以去构建一个更好的谷歌搜索复制品，而是也许有一种更好的方式来帮助人们查找、采取行动并整合信息。实际上，我认为对于某些用例来说，ChatGPT就是这样，希望我们能够将其应用到更多的场景中去。

但我认为，仅仅提出“我们怎样才能比谷歌更好地为你提供前10个排名的网页？”并不那么有趣。也许真正有趣的是说，“我们如何帮助你获得你需要的答案或信息？我们如何在某些情况下帮助你创造它，在其他情况下整合它，或在其他情况下为你指明方向？”很多人只是尝试制造一个比谷歌更好的搜索引擎，但这是一个困难的技术问题，也是一个困难的品牌核生态系统问题。我认为世界不需要谷歌的另一个复制品。

**问：** 将聊天客户端，如ChatGPT，与搜索引擎集成——

**奥特曼：** 那会更酷。

**问：** 这的确很酷，但也很棘手。如果你只是简单地这样做，它会显得很别扭，因为如果你只是把ChatGPT硬塞进去，可能会很奇怪。

**奥特曼：**
你可能已经猜到了，我们对如何做得更好很感兴趣。那将是一个很酷的例子。大语言模型与搜索的结合，我认为还没有人破解这个密码。我很想去做这件事。我认为那会很酷。

**问：** 那么在广告方面呢？你们有没有考虑过ChatGPT的货币化。

**奥特曼：**
从美学角度上说，我有点讨厌广告。我理解互联网之初为了发展不得不依赖广告，但这不过是一个暂时的行业现象。现在世界已经变得更赋予。我喜欢看到人们为ChatGPT付费，并知道他们得到的答案不受广告商的影响。我确信有适合大语言模型的广告模式，也确信有一种以不偏不倚的方式参与交易流的方法，但也很容易想到未来的反乌托邦愿景：你向ChatGPT询问某事，它会说：“哦，你应该考虑购买这个产品”，或者“你应该考虑来这里度假”，或者其他什么。

我不知道到底会是什么样，我们有一个非常简单的商业模式，我挺喜欢的，我知道自己不是被买卖的产品。我知道自己是付费用户，这就是商业模式的工作原理。当我使用Twitter、Facebook、谷歌或其他任何广告支持的产品时，我不喜欢这样。我觉得在人工智能的世界里，情况只会变得更糟，而不会变得更好。

**问：**
是的，我可以想象人工智能会更精准地展示你真正需要的商品和服务的广告，而不是在某个反乌托邦的未来。但是，这样的系统是否总是会导致广告驱动所展示的内容呢？我认为维基百科不做广告是一个非常大胆的决定，但这也使商业模式变得非常具有挑战性。所以你是说OpenAI目前的商业模式从商业角度来看是可持续的吗？

**奥特曼：**
我们必须弄清楚如何实现增长，但看起来我们会找到办法的。如果问题是我是否认为我们可以拥有一个伟大的商业模式，能够支付我们的算力需求而不依赖广告，那么我认为答案是肯定的。

**问：** 我想问你关于安全性和偏见的问题，以及短期和长期的安全性。谷歌最近发布了Gemini
1.5，围绕它引发了很多争议，比如其生成的历史人物多是有色人种。公平地说，它可能偏向了过度 "觉醒"
的一面。所以这是人们担心的问题：如果公司内有人在修改模型的安全性或由其造成的伤害，那么它可能会引入很多符合公司内部意识形态倾向的偏见。你如何处理这个问题？

**奥特曼：**
我们非常努力地避免做这样的事情。我们自己犯过错误，将来也会犯其他错误。我假设谷歌会从这次错误中吸取教训，但他们还是会犯其他错误。这些问题并不容易解决。我们一直在思考的一个问题是，我认为这里有人提出了一个很好的想法，那就是可以把模型应有的行为标准写出来并公开发布，接受大家的反馈，并说：“这是这个模型应有的行为方式”，并解释边缘情况。然后，当模型的行为不符合你的期望时，至少可以清楚地知道这是公司应该修复的错误，还是按照预期行为进行的，你应该讨论政策。而现在，它有时候它会处于模棱两可的状态。而且还有很多其他微妙的场景，每个场景你都可以有自己的判断。我对模型可能表现出的很多方式都持开放态度。但我觉得，你应该明确指出：“这是原则，模型在这种情况下就应该这么做。”

**问：** 你是否觉得在公司内部有这方面的压力，即政治上有偏左或偏右的倾向，这会影响产品或团队？

**奥特曼：**
我觉得很幸运，OpenAI没有像很多公司那样面临我所听说过的挑战。我认为部分原因是每家公司都有一些意识形态的东西。我们有一个关于AGI的信仰，这排除了其他一些东西。与我所听到的许多其他公司相比，我们在文化争议中的卷入程度要小得多。尽管这种政治偏见以各种微妙的方式渗透进来了，但并不明显。我认为我们肯定有过一些冲突，就像任何公司一样，但我不认为我们在这个问题上经历过像在其他公司听说的那种情况。

**问：**
随着人工智能变得越来越强大，这将是人类真正需要思考的问题。因此，OpenAI的大多数员工都会思考“安全性”，或者至少会在某种程度上思考“安全”这个词。

**奥特曼：** 广义上来说是这样。没错。

**问：** 我想知道，这个问题有怎样全面而广泛的定义？可能会造成的不同危害有哪些？这是技术层面的问题还是几乎涉及安全威胁？

**奥特曼：**
这可能涉及所有这些问题。是的，我想说会有人，国家行为者试图窃取这个模型。这将包括所有的技术对齐工作。这将涉及社会影响、经济影响。这不仅仅是我们有一个团队在思考如何对齐模型。要实现好的结果，真的需要整个公司的努力。

11 跨越到GPT-5：变得更聪明

**问：** 尽管你现在还不能透露太多细节，但我还是想继续讨论这个话题。你对GPT-4到GPT-5的飞跃中哪些方面感到兴奋？

**奥特曼：**
令我兴奋的是，它会变得更聪明。我知道这样的回答听起来可能不够严肃，但我认为真正激动人心的事情是，它并不是在某个方面变得更好，而在各个方面变得更好。我认为这非常酷。

**问：**
是的，确实有那么一刻，就像魔法一样。我指的是，当你遇到某些人，与他们相处，与他们交谈时，你可能说不上来是什么原因，但他们就是能够理解你。这并不是真正的智慧，而是某种其他的东西。我想这大概就是我描述GPT进步的方式。这并不是说，你可以指出“看，你没有理解这个或那个”，而是它在多大程度上与你产生一种智力上的联系。你感觉到它理解了你那些糟糕的、零散的提示背后的深层问题。是的，我也对此感到兴奋。毕竟，我们所有人都喜欢被聆听，被理解。

**奥特曼：** 那是肯定的。

**问：**
那是一种奇怪的感觉。即使是在编程时，当你编写程序并说出某些内容，或者GPT可能完成的某些内容时，当它理解你的想法时，那种感觉真是太棒了。我期待它在这方面能变得更好。展望未来，在编程方面，你认为5年、10年后人类会进行多少编程工作？

**奥特曼：** 我认为还会有很多，但我认为它的形式会非常不同。也许有些人会完全用自然语言编程。

**问：** 完全用自然语言？

**奥特曼：** 我是说，没有人通过编写代码来编程了。有些人还会这么做，但现在已经没有人再使用打孔卡来编程了。

**问：** 编程确实挺难的。那么，要怎样才能迈过最后那 1% 的鸿沟呢？这到底有多困难啊？

**奥特曼：** 我认为在大多数情况下，最擅长这项技能的人会使用多种工具。他们会用自然语言做一些工作，当需要利用C语言编写代码时，他们也会这么做。

**问：** 我们会在某个时候看到OpenAI开发的人形机器人或人形机器人大脑吗？

**奥特曼：** 在某个时候会的。

**问：** 你认为实体化的人工智能对你有多重要？

**奥特曼：**
我觉得如果我们有了通用人工智能，但唯一能在现实世界中完成事情的方式是让人类去完成，那将是很令人沮丧的。因此，我真的希望在这个过渡阶段，我们也能得到人形机器人或某种能在现实世界操作的机器人。

**问：** OpenAI在机器人方面有些研究和积累，但在伦理方面并没有取得什么进展。

**奥特曼：**
我们是一家规模不大的公司。我们必须真正集中精力。此外，当时研发机器人之所以艰难，并非因为有正确的理由。不过，我们将在某个时候以某种方式重新投入机器人研究。

**问：** 这听起来令人觉得有点儿不安，因为会让人想起《终结者》一样的机器人。

**奥特曼：** 我们会重新投入机器人研发工作。当然，我们不会把自己变成机器人。

12 AGI

**问：** 你认为我们何时会有通用人工智能（AGI）？

**奥特曼：**
我以前很喜欢猜测这个问题。但我后来意识到，这个问题问得不够准确，因为人们对AGI的定义差异极大。因此，我认为谈论我们将何时建立能够执行X、Y或Z能力的系统更有意义，而不是模糊地谈论何时会跨越某个里程碑。AGI也不是终点，它更接近一个起点，但它其实更多是一个里程碑。为了不逃避这个问题，我预计在2030年之前，或者可能比那更早，我们将拥有非常强大的系统，我们看着它们会说：“哇，那真是太了不起了。”前提是如果我们现在能看到的话。也许我们到了那个时候已经适应了。

**问：** 但如果你拿出ChatGPT，哪怕是3.5版本，你把它展示给艾伦·图灵（Alan
Turing），或者是90年代的人看，他们可能会说：“这绝对是通用人工只能了。”当然，这不是绝对，但有很多专家会说：“这就是通用人工智能。”

**奥特曼：**
是的，但我认为3.5并没有改变世界。它可能改变了世界对未来的期望，这实际上非常重要。它也确实让更多的人认真对待这个领域，并让我们走上了新的轨迹。这同样也非常重要。所以，我不想贬低它的价值。我觉得完成这一成就后，我就可以退休了，并对我的职业生涯感到相当满意。但是将它视作一个具体物件来看，我不认为我们会回头看那个时刻，并说，“那是一个真正改变世界本身的分水岭。”

**问：** 对你来说，你是在寻找世界上某种真正重大的转变吗？

**奥特曼：** 对我来说，这正是AGI所暗示的一部分。

**问：** 奇点级别的转变吗？

**奥特曼：** 不，绝对不是。

**问：** 但就像互联网，或者像谷歌搜索所做的那样，这是一个重大的转变。你认为现在是一个转折点吗？

**奥特曼：**
你觉得现在全球经济与GPT-4发布之前相比有什么不同吗？我猜你会说没有。我的意思是，人们对AGI的定义各不相同，每个人都有各自的理解。但对我来说，我认为这应该是其中的一部分。

**问：** 也可能会有重大的戏剧性时刻。对你来说，AGI做的什么会让你印象深刻？如果你独自一人在房间里与这个系统对话。

**奥特曼：**
这对我来说很重要。我不知道这是否是正确的定义。我认为当一个系统能够显著提高世界上科学发现的速率时，那就是非常了不起的事情。我相信大多数真正的经济增长都来自科学和技术的进步。

**问：** 但实际上，科学发现的速度是可以衡量的。但即使只是看到一个系统拥有真正新颖的、科学的直觉，那也会令人难以置信。

**奥特曼：** 是的。

**问：** 你很有可能会成为第一个与AGI互动的人。你打算和它聊些什么？

**奥特曼：**
我想这里的研究人员肯定会在我之前做这件事。但我其实已经想过很多次了。就像我们之前讨论的，虽然这可能不是一个好的出发点，但如果有人告诉我，“好了，山姆，我们完成了。这是一台笔记本电脑，这就是AGI。你可以去和它交流了。”我发现我很难说出我会问什么，以及我期待第一个AGI能够回答什么。第一个AGI可能不会像我想象的那样，比如，“给我解释一下物理学的大统一理论，也就是物理学的万物理论。”我很想问这个问题，也很想知道答案。

**问：** 是非题。然后基于这个模式，你还会问：还有其他外星文明存在吗？有还是没有？你的直觉是什么？

**奥特曼：** 我不期望这个第一个AGI能够回答任何这些问题，哪怕是是非题。但如果它能，那这些问题肯定会排在我的问题列表的前列。

**问：** 率先开发出AGI的人会掌握很大的权力，你相信自己能够妥善运用这种权力吗？

**奥特曼：**
我会很诚实地回答这个问题。我本来想说，而且我现在仍然相信，无论是我还是其他任何一个人，都不应该完全控制OpenAI或AGI。我认为我们需要一个健全的治理体系。我可以指出去年我们董事会风波中的一堆问题，比如最初我并没有反对，只是说，“好吧，这是董事会的意愿，尽管我认为这是一个非常糟糕的决定。”但后来，我确实反对了，我可以解释其中的细微差别，以及为什么我认为后来反对是合理的。但正如许多人观察到的那样，尽管董事会拥有解雇我的法律权力，但在实际操作中情况并没有那么简单。这本身就是一种治理失败。

现在，我觉得自己完全为这些具体情况辩护，而且我相信大多数人也会同意这一点，但这确实让我更难直视你的眼睛说，“嘿，董事会可以随时解雇我。”一直以来，我都不希望拥有对OpenAI的超级投票控制权。我从未想过，也从未拥有过。即使经历了所有这些疯狂的事情，我仍然不想要这种权力。我仍然认为不应该由任何一家公司做出这些决定，我们真的需要政府来制定规则。

我意识到，这可能意味着像马克·安德森（Marc
Andreessen）这样的风投家会指责我试图讨好监管机构，我宁愿在这里被误解，尽管那不是真的。我认为随着时间的推移，我们为什么这样做的重要性将会得到证明。但我承认，我在OpenAI的决策过程中也犯了很多错误，当然也有很多好的决策，我对此感到自豪。
但我不认为应该，也不会有任何一个人来控制整个局面。现在的局势已经变得过于庞大，它正以一种积极健康的方式在整个社会中发展。我不认为任何个人应该控制 AGI
或者这个朝 AGI 迈进的整个进程。

**问：** 你害怕失去对AGI本身的控制吗？很多人担心存在性风险，不是因为国家行为者，也不是因为安全顾虑，而是因为人工智能本身。

**奥特曼：** 目前在我所看到的情况中，这并不是我最担心的问题。未来可能会有时候这再次成为我最担心的问题，但至少现在它不是。

**问：** 你的直觉告诉你，为什么这件事不值得担心？是因为还有很多其他事情需要担心？还是你认为自己可能会感到惊讶？

**奥特曼：**
当然可能。说它不是我最担心的问题并不意味着我认为我们不需要解决。我认为我们需要努力解决这些问题。这非常棘手，但我们这里有很多优秀的人在做这方面的工作。同时，我认为还有很多其他事情我们也必须妥善应对。

**问：** 对你来说，现在并不是超级容易就能跳出这个框架，连接到互联网——

**奥特曼：**
我们之前讨论过戏剧性风险，而这正是一种戏剧性风险。它能够左右人们如何思考这个问题。有一大群非常聪明、我认为非常善良的人工智能安全研究人员对这个问题感到非常困惑，我认为他们在这个问题上没有取得太多进展。事实上，我很高兴他们这样做，因为我认为我们确实需要更多地思考这个问题。但是，我也认为这种专注挤压了对话空间，使得其他同样重大的AI
相关风险被边缘化了。

**问：**
鉴于Sora生成模拟世界的能力，我想问你一个可能有点“脑洞大开”的问题。这会让你更相信我们可能生活在一个模拟现实中，它也许是由人工智能系统生成的？

**奥特曼：**
在某种程度上会的。但我不认为这是最有力的证据。我认为我们能够生成世界这一事实，应该会在一定程度上提高每个人对此的接受程度或者至少增加一些对这个观念的开放性。但我确信，我们总有一天能够做出像Sora这样的东西。它到来的速度比我预想的要快，不过我认为这并没有给我带来太大的惊讶。

**问：**
但可以预见的是，它会变得越来越好，我们有理由相信它可以生成全新的世界，它们基于某些训练数据，但当你看到它们时，它们是全新的，这让人不禁思考，创造这样的宇宙，构建一个超现实且像照片一般逼真的整个电子游戏世界，其实是多么容易。再进一步思考，我们带上VR头显，沉浸在这样的世界里会有多容易，而当我们迈向更基于物理规律的层面时，又会简单到什么程度呢？

**奥特曼：**
最近有人对我说，我认为这是一个非常深刻的见解，存在一些听起来很简单但非常迷幻的见解。例如平方根函数，求4的平方根很轻松，2的平方根可能是一种新类型的数字。但是一旦我提出这个简单的平方根函数的概念，你可以向一个孩子解释，甚至通过看一些简单的几何图形就能理解，那么你就可以问“负一的平方根是什么？”这就是它带有迷幻气息的原因。这个问题会将你引入一个完全不同的现实维度。

你可以举出很多其他例子，但我认为这个简单的平方根运算符能够带来如此深刻的见解和新的知识领域的想法在很多方面都适用。我认为有很多这样的运算符，它们让人们觉得他们喜欢的任何版本的模拟假说都比他们之前认为的更有可能。但对我来说，Sora的工作甚至不在我排名前五的优先事项之内。

13 外星人

**问：** 当你仰望繁星点点的夜空时，你认为宇宙中还存在其他的外星文明吗？也是拥有智慧的那种？

**奥特曼：** 我非常想相信答案是肯定的。我发现费米悖论非常难以理解。

**问：** 我发现智能不擅长处理这样的问题，这挺让人害怕的。但与此同时，我坚信，宇宙中肯定存在大量的智慧外星文明。可能只是穿越太空非常艰难而已。

**奥特曼：** 很有可能。

**问：**
这也让我思考智能的本质。也许我们对智能的样子视而不见，也许人工智能会帮助我们认识到这一点。智能并不像智商测试和简单的解谜那样简单，它有更深层次的东西。关于人类的未来，你有什么希望？

**奥特曼：**
我认为过去已经给了我们很多线索。我是说，我们看看人类在并不漫长的时间里所做的事情，虽然存在巨大的问题、深刻的缺陷，还有许多让人深感羞耻的事情。但总体上，这是非常振奋人心的。这给了我很多希望。

**问：** 我们正共同努力迈向更美好的未来。

**奥特曼：**
我一直好奇的是，通用人工智能将更接近于某个单独的大脑，还是更像是联系我们每个人的社会基础设施？你从高曾祖父母那里继承的基因变异并不大，但你所具备的能力却截然不同，你所知道的东西也截然不同。这并不是因为生物学上的演变。我的意思是，你可能变得更健康了一些，有了现代医学的帮助，你可能吃得更好。但重要的是，你拥有的是我们所有人共同构建的知识和技能的框架。没有任何一个人会单独去制造iPhone。没有任何一个人会独自去发现所有科学知识，但你能够利用这些知识。这赋予了你难以置信的能力。在某种程度上，这是我们所有人共同创造的成果，这让我对未来充满了希望。那是一项集体努力的成果。

**问：** 我们确实站在巨人的肩膀上。你之前提到，当我们遇到戏剧性的人工智能风险时，有时你可能会担心自己的生命安全。你有没有想到过自己的死亡吗？你害怕吗？

**奥特曼：**
如果我知道自己明天会被枪杀，而我今天就知道了，我会想，“哦，那太遗憾了。我想看看接下来会发生什么。多么不可思议、多么有趣的时刻。”不过，我最主要的感觉还是会非常感激我所拥有的生活。（编译/金鹿）

