# ChatGPT每年电费2亿？！日耗电量≈1.7万个家庭，网友：挺值

# ChatGPT每年电费2亿？！日耗电量≈1.7万个家庭，网友：挺值

ChatGPT居然这么费电？

最新的等式出现了：

**ChatGPT日耗电量≈1.7万家庭日耗电量。**

什么概念？一年光电费就要花2亿！

美国普通家庭平均单日用电29千瓦时，而ChatGPT的单日用电量超过了**50万千瓦时** 。

（美国商业用电一度约为0.147美元也就是1.06元，相当于一天53万元）

消息一出就直接冲上热搜第一了。

![](https://inews.gtimg.com/news_bt/Oiv_it7Cu5t53q458QzNaE2dd2aaqNjlsrJy8FRAIeDbwAA/1000)

除了OpenAI，**谷歌** 也“不容小觑”：

在谷歌搜索中应用生成式AI技术，谷歌每年的耗电量将高达290亿千瓦时，也就是每天约7900万度（？）。

而在未来，AI这一“吃电巨兽”的食量还会更惊人。

数据统计：

到2027年，人工智能数据中心的用电量将和荷兰、瑞典等小国用电量相当。

有网友看完表示：

这是利好光伏和风电？

![](https://inews.gtimg.com/news_bt/OkXhMm2ZF1plb9eAJJP3GOBZT3m_p3zbUsZOryDz_zNYsAA/1000)

所以AI最后拼的是谁发电多、谁发电成本低？

![](https://inews.gtimg.com/news_bt/O20tfscE9su2TJVqU6somRXWoNuNRe7FNhm2pc-
LFCQ8cAA/1000)

01 AI要耗多少电？

如上数据来自一篇论文《The growing energy footprint of artificial intelligence》。

作者是荷兰数字经济学家Alex de Vries，他通过英伟达、OpenAI、谷歌等公开数据进行估算。

结果就得出了很多意想不到的结论。

**首先，现在大模型训练时期的耗电量和推理阶段相比，已经不值一提了** 。

SemiAnalysis数据显示，OpenAI需要**3617台** 英伟达HGX A100、共28936个GPU来支持ChatGPT推理。

ChatGPT每天需要响应1.95亿次请求，预计每天需要消耗564兆瓦时电力，每个请求大约2.9瓦时。

而GPT-3整个训练阶段的耗电量预估为1287兆瓦时，是ChatGPT大约4天的消耗量。

谷歌报告也表示，2019-2021年，与人工智能相关的能源消耗中有60%来自推理部分。

因此论文提出未来研究AI用电量时，更应该从全周期角度考量。

但这也与模型再训练频率、模型性能与功耗之间的平衡有关系。比如BLOOM在推理阶段的耗电量就显著降低。

![](https://inews.gtimg.com/news_bt/Oz3q3sF1yF0PIbCjSZFssWn9_iq-
ghw3JtuR9XAqkGzmAAA/1000)

**其次，搜索引擎如果用上AI，耗电量还会更高。**

谷歌方面曾在去年2月表示，AI响应请求的成本可能是普通搜索的10倍。

数据显示，使用一次谷歌搜索消耗的电量是**0.3瓦时** 。这和上面分析给出的数据相呼应。

如果要将大模型能力植入到谷歌搜索中，预计需要**512821** 个HGX
A100，按照每台设备功耗为6.5千瓦来计算，每天将需要80吉瓦时的电力消耗，一年需要29.2太瓦时。

目前谷歌每天需要处理高达90亿次搜索，换算一下，平均每个请求要消耗6.9-8.9瓦时，已经是普通搜索的20倍+。

![](https://inews.gtimg.com/news_bt/OEKm7H7KSd7jp-
gO4M2kLscpIbK8C-8NNPL4ZKndthMQ8AA/1000)

同样的现象在英伟达的财报数据中也可以看到。

去年第二季度，英伟达收入创纪录，其中数据中心部门较上季度相比增长了141%，这表示AI方面的需求扩增。

今年，英伟达AI服务器出货量可能达到150万台，总功耗可能达到9.75-15.3吉瓦。这一数量级的服务器，每年的用电量将达到85.4-134太瓦时。

**不过AI用电量会一路飙升吗？**

研究认为也不一定。

哪怕像谷歌这样在全球拥有数十亿用户的厂商，也会慎重考虑AI与搜索引擎的融合。硬件、软件和电力成本压力下，厂商脚步或许没那么快。

硬件生产本身还受到掣肘，AI热潮使得台积电CoWoS先进封装产能吃紧，但新建工厂真正可能开始批量生产要等到2027年，这或许也会影响英伟达的出货量。

以及模型本身的算法和架构也会让AI功耗在一定程度上降低。

最终研究认为，关于AI用电量的问题，过于悲观或乐观都不可取。

短期内，在各种资源因素影响下，AI用电量增速会被抑制；但硬件和软件的能效提高，显然也无法抵消长期的电力需求增长。

总之，作者认为在AI开发方面，还是不要铺张浪费的好。监管机构也需要考虑要求厂商披露相关数据，提高整个AI供应链的透明度，从而更好了解这一新兴技术的环境成本。

实际上，此前关于AI消耗资源的话题已经多次引发讨论。

有研究指出，到2027年，数据中心人工智能的用电量将与荷兰或瑞典等小国的用电量相当。

加州大学河滨分校研究表明，问ChatGPT5-50个问题，就可消耗500毫升水。

因为AI超算数据中心需要大量水来散热，微软也承认用水是训练模型的一大成本，从2021年到2022年，其全球用水量飙升了34%，相比研究AIGC前急剧增加。

![](https://inews.gtimg.com/news_bt/O_nE9kYNFl8nNz1e9uPuInrULIyog_YPfNzEW2w66_kTgAA/1000)

02 网友：也要看产出

除了微博，#ChatGPT日耗电超50万度#的消息也在知乎冲上热榜第三。

![](https://inews.gtimg.com/news_bt/OS5Tyok_38ErXa3PYbvLG5djiGq5Moh-
wc5r8F2rnWyuUAA/1000)

尽管这一数据看起来惊人，但不少网友都表示：

我们还是需要比较一下投入产出。

![](https://inews.gtimg.com/news_bt/OaH5VVgGpGYEi8JRbmVxmAN0ocAWlM9HPt-
Rjovpop14AAA/1000)

知乎网友@段小草就浅算了一下：

一天50万度电，1.7万个美国家庭。但美国有1.2亿个家庭，也就是**只需万分之一的家庭用电，就能支撑一个服务全球TOP 1的AI产品、服务几亿用户**
，这还是在浪费能源破坏环境吗？

言外之意，如下所说（来自知乎网友@桔了个仔）：

**ChatGPT创造的价值其实远超它的能耗。**

和某些技术（咳咳，懂得都懂）的耗电量相比，它可能更不值一提了。

![](https://inews.gtimg.com/news_bt/Om00KglPJ5nBbeo7daIBG6WAx2LpuNrxRZW0KjCXnVQrcAA/1000)

所以，有人（知乎网友@玩吾伤智）直接就表示，这则消息应该这么理解：

震惊， 只需要1.7万普通家庭的电量即可满足ChatGPT的一日用电需求。（手动狗头）

![](https://inews.gtimg.com/news_bt/OyJ_vDwUxnFbQp6ok2vZpXhthudjR4OGAJ-
Ij9dcwiBG4AA/1000)

咳咳，有意思的是，上面的答主@段小草还提到了一篇论文，题为《The Carbon Emissions of Writing and lllustrating
Are Lower for Al than for
Humans》，讲的是**AI在画画和写作上的碳排放量一个比人类少310到2900倍，一个比人类少130到1500倍** 。

![](https://inews.gtimg.com/news_bt/OPLTdlhwyBcvfc-5TDSTkFzM10XPDd2l62HugwVuYS07gAA/1000)

这样看来，AI甚至算得上**“节能减排的先锋”** 。（手动狗头）

呐，我们还是早点洗洗睡、关注GPT-5什么时候发吧。

![](https://inews.gtimg.com/news_bt/O_PHXhPtE8X0meWF1duCkRDthONR-
enZusR0UE2kiC-dUAA/1000)

03 奥特曼：我们需要可控核聚变

话又说回来，尽管比起收益，ChatGPT一日1.7万个家庭的能耗还不值一提，但AI能耗确实也是一个值得关注的问题。

而这点，奥特曼早就在“担忧”了。

在今年1月的一场达沃斯会议中，他就表示：

人工智能的未来取决于清洁能源的突破。

![](https://inews.gtimg.com/news_bt/Owli68F-u28eGJFr6dnHEG1XEzvj9YkbjtPcyjmrTX_usAA/1000)
_图源Digwatch_

具体而言，他认为：

随着技术越来越成熟，AI将消耗越来越大量的电力，**如果能源技术无法突破，就无法实现这一目标** （即让AI技术释放全部潜力）。

而现在，公众还不是很了解这个需求究竟有多大，奥特曼本人表示也远超他的预期。

至于如何提升能源产量，他也直言：

需要**可控核聚变** ，或者更便宜的太阳能及存储等等。

——说起可控核聚变，奥特曼其实早就押注了一家相关公司，名叫**Helion** 。

![](https://inews.gtimg.com/news_bt/OkETLAjzSfcP4ZUGfRwTsdtoXO_xlB8LeHPvBiRbHYYWcAA/1000)

他在它身上投资了3.75亿美元，这是他以个人名义投资的最大一笔。

除此之外，奥特曼的“爸爸”**微软** 也押注了这家公司。

据了解，Helion成立于2013年，目前约150+员工。他们预计将在2028年上线50兆瓦规模的可控核聚变发电项目，微软将率先采购。

明敏 丰色 发自 凹非寺

量子位 | 公众号 QbitAI

原报告：

https://www.cell.com/joule/abstract/S2542-4351(23)00365-3

参考链接：

[1]https://weibo.com/1642634100/O4lb78n3U?refer_flag=1001030103_

[2]https://www.businessinsider.com/chatgpt-uses-17-thousand-times-more-
electricity-than-us-household-2024-3

[3]https://www.newyorker.com/news/daily-comment/the-obscene-energy-demands-of-
ai

[4]https://www.theverge.com/2024/1/19/24044070/sam-altman-says-the-future-of-
ai-depends-on-breakthroughs-in-clean-energy

[5]https://www.zhihu.com/question/647926823

