# 一线 | 亚马逊AWS发布新人工智能芯片，并加强与英伟达合作

# 一线 | 亚马逊AWS发布新人工智能芯片，并加强与英伟达合作

腾讯新闻《一线》 纪振宇 发自拉斯维加斯

亚马逊的云服务部门AWS
美国时间11月28日在Reinvent大会上，发布了其最新的Trainium2人工智能芯片和通用的Graviton4处理器。AWS还表示，将提供访问英伟达的最新H200
GPU。

自去年底ChatGPT首次发布以来，新一轮的围绕大语言模型的热潮来临，作为云服务提供商，亚马逊AWS也开始在该领域重点发力。

对于这一轮人工智能大语言模型，AWS的策略是“两条腿走路”，一方面自研芯片及提供基础大语言模型服务能力，另一方面加强与英伟达的合作。

此次亚马逊发布自研性能强大的人工智能芯片Trainium2，以及Graviton
4处理器，该处理器基于Arm架构，AWS称其比Intel或AMD的芯片能效更高。Graviton4承诺比现有的Graviton3芯片性能提高30%，实现AWS所说的更好的性价比。

AWS称，目前已有超过50,000个AWS客户在使用Graviton芯片。初创公司Databricks和得到亚马逊投资的OpenAI竞争对手Anthropic计划使用新的Trainium2芯片构建模型，据亚马逊称，其性能比原始型号提高了四倍。

今年早些时候，亚马逊发布了称为Bedrock的人工智能云服务，向客户提供亚马逊自主研发的基础大模型Titan的能力。

亚马逊首席执行官Andy
Jassy此前表示，许多希望使用大语言模型的公司需要花费数十亿美元和许多年来训练模型，对它们来说更现实可行的路径是使用现有的大模型并能够根据他们自己的需求来进行定制，而这就是亚马逊Bedrock服务所提供的。

除了自研芯片和提供大语言模型能力外，亚马逊还进一步加强与英伟达的合作。在当天的Reinvent大会上，英伟达首席执行官黄仁勋也到场，与AWS
首席执行官Adam Selipsky同台对话。

AWS表示，将运行超过16,000个Nvidia GH200 Grace Hopper Superchips，其中包含H100
GPU和Nvidia的基于Arm的通用处理器，供Nvidia的研发团队使用。

自2006年发布EC2和S3服务以来，AWS已经推出了200多种云产品。当天AWS并没有宣布搭载Nvidia
H200芯片的虚拟机Instance或依赖其Trainium2硅片Instance的发布日期。在未来几个月内，这些Graviton4将商用化之前，客户可以开始测试它们。

由人工智能大语言模型所掀起的新一轮人工智能热潮，也让云服务市场进入到新的竞争阶段。与OpenAI深度合作的微软在本月早些时候也公布了自研AI芯片Maia
100，并表示云服务Azure将搭载英伟达H200 GPU；谷歌也通过旗下云服务Model
Garden向用户提供整套的大语言模型基础能力，帮助用户更便利地定制产品。

根据市场研究机构Statista数据显示，截至今年第二季度，AWS在云服务市场的占有率仍高居第一，达到32%，微软的Azure紧随其后，市场占有率达到22%，谷歌云服务位列第三，达到11%。

